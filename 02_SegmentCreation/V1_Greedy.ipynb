{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d935d97",
   "metadata": {},
   "source": [
    "# Segments V1 (Edges only) — batch-aware greedy MST\n",
    "\n",
    "**Goal**  \n",
    "Create a **greedy MST (Prim)** per dataset and save it under a **solutions** subfolder\n",
    "inside each dataset. Before creating a solution, the notebook **checks if it already exists**\n",
    "and **skips** that dataset.\n",
    "\n",
    "**What counts as a dataset?**  \n",
    "A folder that contains a top-level `nodes.csv` (from your nodes-only generator).\n",
    "\n",
    "**Outputs** (per dataset, inside `<dataset>/solutions/<solution_name>/`)\n",
    "- `edges.csv` — columns: `u, v, length_km`\n",
    "- `adjacency.csv` — `NxN`, 1 if edge exists, else 0\n",
    "- `cost.csv` — `NxN`, edge length in km (`0` on diagonal; `inf` if no edge)\n",
    "- `segments_preview.png`\n",
    "- `solution_meta.json`\n",
    "\n",
    "**Usage**\n",
    "- **Option A (batch):** set `dataset_root` to your `00_Datasets` root.\n",
    "- **Option B (single dataset):** leave `dataset_root=None` and set `nodes_csv_path`.\n",
    "\n",
    "Only **new** solutions are created; existing ones are **skipped**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d850a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanning datasets under: C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds01_seed42_tp3M_nc15\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds02_seed43_tp3.5M_nc18\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds03_seed44_tp4M_nc20\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds04_seed45_tp2.5M_nc22\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds05_seed46_tp5M_nc24\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds06_seed47_tp5.5M_nc26\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds07_seed48_tp1M_nc28\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds08_seed49_tp6.5M_nc30\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds09_seed50_tp0.5M_nc32\\solutions\\v1_greedy_mst\n",
      "[OK]   Created solution → C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\\sv1.2\\dv0.1_ds10_seed51_tp1.5M_nc35\\solutions\\v1_greedy_mst\n",
      "\n",
      "[Segments V1] Done. Datasets scanned: 10 | New solutions: 10\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Jupyter notebook cell — Segments V1 (Edges only) — batch-aware greedy MST\n",
    "\n",
    "Goal\n",
    "-----\n",
    "Create a **greedy MST (Prim)** per dataset and save it under a **solutions subfolder\n",
    "inside each dataset**. Before creating a solution, the notebook **checks if it already exists**\n",
    "and **skips** that dataset.\n",
    "\n",
    "What counts as a dataset?\n",
    "- A folder that contains a top-level `nodes.csv` (from your nodes-only generator).\n",
    "\n",
    "Outputs (per dataset, inside `<dataset>/solutions/<solution_name>/`)\n",
    "- `edges.csv`          : u, v, length_km\n",
    "- `adjacency.csv`      : NxN, 1/0 connectivity\n",
    "- `cost.csv`           : NxN, length_km (0 diag, inf if no edge)\n",
    "- `segments_preview.png`\n",
    "- `solution_meta.json`\n",
    "\n",
    "Usage\n",
    "-----\n",
    "Option A (batch over many datasets): set `dataset_root` to your 00_Datasets root.\n",
    "Option B (single dataset): leave `dataset_root=None` and set `nodes_csv_path`.\n",
    "\n",
    "Only **new** solutions are created; existing ones are **skipped**.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Tuple, Dict, Iterable\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Config\n",
    "# ------------------------------\n",
    "@dataclass\n",
    "class SegV1Config:\n",
    "    seed: int = 42  # not used by Prim, kept for symmetry/metadata\n",
    "\n",
    "    # Batch mode (set this to your datasets root; e.g., \"...\\\\00_Datasets\")\n",
    "    dataset_root: str | None = None\n",
    "\n",
    "    # Single-dataset mode (used only if dataset_root is None)\n",
    "    nodes_csv_path: str | None = None\n",
    "\n",
    "    # Where to write solutions inside each dataset\n",
    "    solutions_subdir: str = \"solutions\"\n",
    "    solution_name: str | None = None  # None → \"v1_greedy_mst\"\n",
    "\n",
    "    # Plot settings\n",
    "    label_lengths: bool = True\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Helpers\n",
    "# ------------------------------\n",
    "def _load_nodes(nodes_csv_path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(nodes_csv_path)\n",
    "    required = {\"id\", \"x_km\", \"y_km\"}\n",
    "    missing = required - set(df.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"nodes.csv missing columns: {missing}\")\n",
    "\n",
    "    # sort by id and make sure ids are 0..N-1; if not, remap\n",
    "    df = df.sort_values(\"id\").reset_index(drop=True)\n",
    "    if not np.array_equal(df[\"id\"].to_numpy(), np.arange(len(df))):\n",
    "        df.insert(0, \"orig_id\", df[\"id\"].values)\n",
    "        df[\"id\"] = np.arange(len(df), dtype=int)\n",
    "    df = df.set_index(\"id\", drop=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _pairwise_distances(x: np.ndarray, y: np.ndarray) -> np.ndarray:\n",
    "    X = x[:, None] - x[None, :]\n",
    "    Y = y[:, None] - y[None, :]\n",
    "    return np.sqrt(X * X + Y * Y)\n",
    "\n",
    "\n",
    "def _solution_dir(dataset_dir: str, solutions_subdir: str, solution_name: str) -> str:\n",
    "    sol_dir = os.path.join(dataset_dir, solutions_subdir, solution_name)\n",
    "    os.makedirs(sol_dir, exist_ok=True)\n",
    "    return sol_dir\n",
    "\n",
    "\n",
    "def _solution_exists(sol_dir: str) -> bool:\n",
    "    \"\"\"Consider it 'exists' if edges.csv is present (lightweight check).\"\"\"\n",
    "    return os.path.exists(os.path.join(sol_dir, \"edges.csv\"))\n",
    "\n",
    "\n",
    "def _iter_datasets_with_nodes(dataset_root: str, solutions_subdir: str) -> Iterable[str]:\n",
    "    \"\"\"\n",
    "    Yield dataset directories that contain a top-level nodes.csv.\n",
    "    Skips any nested 'solutions' subfolders.\n",
    "    \"\"\"\n",
    "    for root, dirs, files in os.walk(dataset_root):\n",
    "        # do not descend into any 'solutions' directories\n",
    "        dirs[:] = [d for d in dirs if d != solutions_subdir]\n",
    "        if \"nodes.csv\" in files:\n",
    "            yield root\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Core (Segments V1 — Prim's MST)\n",
    "# ------------------------------\n",
    "def build_mst_greedy_prim(D: np.ndarray) -> List[Tuple[int, int, float]]:\n",
    "    \"\"\"Prim's algorithm over the complete graph with metric distances.\"\"\"\n",
    "    n = D.shape[0]\n",
    "    in_mst = np.zeros(n, dtype=bool)\n",
    "    parent = -np.ones(n, dtype=int)\n",
    "    key = np.full(n, np.inf)\n",
    "\n",
    "    # start from node 0\n",
    "    key[0] = 0.0\n",
    "    for _ in range(n):\n",
    "        # pick min key among nodes not yet in the MST\n",
    "        u = int(np.argmin(np.where(in_mst, np.inf, key)))\n",
    "        in_mst[u] = True\n",
    "        # update keys of neighbors\n",
    "        for v in range(n):\n",
    "            if not in_mst[v] and D[u, v] < key[v]:\n",
    "                key[v] = D[u, v]\n",
    "                parent[v] = u\n",
    "\n",
    "    # gather edges (skip root 0)\n",
    "    edges: List[Tuple[int, int, float]] = []\n",
    "    for v in range(1, n):\n",
    "        u = int(parent[v])\n",
    "        if u < 0:\n",
    "            raise RuntimeError(\"Unexpected: MST parent missing — check input.\")\n",
    "        edges.append((u, v, float(D[u, v])))\n",
    "    return edges\n",
    "\n",
    "\n",
    "def edges_to_matrices(n: int, edges: List[Tuple[int, int, float]]) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    A = np.zeros((n, n), dtype=int)\n",
    "    C = np.full((n, n), np.inf, dtype=float)\n",
    "    np.fill_diagonal(C, 0.0)\n",
    "    for u, v, w in edges:\n",
    "        A[u, v] = A[v, u] = 1\n",
    "        C[u, v] = C[v, u] = w\n",
    "    return A, C\n",
    "\n",
    "\n",
    "def preview_segments(nodes: pd.DataFrame,\n",
    "                     edges: List[Tuple[int, int, float]],\n",
    "                     save_path: str,\n",
    "                     label_lengths: bool = True) -> None:\n",
    "    minx, miny = nodes[[\"x_km\", \"y_km\"]].min()\n",
    "    maxx, maxy = nodes[[\"x_km\", \"y_km\"]].max()\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    for u, v, w in edges:\n",
    "        x1, y1 = nodes.loc[u, [\"x_km\", \"y_km\"]]\n",
    "        x2, y2 = nodes.loc[v, [\"x_km\", \"y_km\"]]\n",
    "        plt.plot([x1, x2], [y1, y2])\n",
    "        if label_lengths:\n",
    "            xm, ym = (x1 + x2) / 2.0, (y1 + y2) / 2.0\n",
    "            plt.text(xm, ym, f\"{w:.1f}\", fontsize=7, ha=\"center\", va=\"center\",\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.15\", fc=\"white\", ec=\"none\", alpha=0.6))\n",
    "    # nodes\n",
    "    if \"pop\" in nodes.columns:\n",
    "        s = 10 + 90 * np.sqrt(nodes[\"pop\"].to_numpy() / nodes[\"pop\"].max())\n",
    "    else:\n",
    "        s = np.full(len(nodes), 40.0)\n",
    "    plt.scatter(nodes[\"x_km\"], nodes[\"y_km\"], s=s)\n",
    "\n",
    "    plt.title(\"Segments — V1 greedy MST (numbers = length km)\")\n",
    "    plt.xlabel(\"x (km)\"); plt.ylabel(\"y (km)\")\n",
    "    plt.xlim(minx, maxx); plt.ylim(miny, maxy)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.tight_layout(); plt.savefig(save_path, dpi=150); plt.close()\n",
    "\n",
    "\n",
    "def write_solution(nodes: pd.DataFrame,\n",
    "                   edges: List[Tuple[int, int, float]],\n",
    "                   dataset_dir: str,\n",
    "                   solutions_subdir: str,\n",
    "                   solution_name: str,\n",
    "                   label_lengths: bool,\n",
    "                   seed: int) -> Dict[str, str]:\n",
    "    sol_dir = _solution_dir(dataset_dir, solutions_subdir, solution_name)\n",
    "\n",
    "    edges_path = os.path.join(sol_dir, \"edges.csv\")\n",
    "    adj_path = os.path.join(sol_dir, \"adjacency.csv\")\n",
    "    cost_path = os.path.join(sol_dir, \"cost.csv\")\n",
    "    preview_path = os.path.join(sol_dir, \"segments_preview.png\")\n",
    "    meta_path = os.path.join(sol_dir, \"solution_meta.json\")\n",
    "\n",
    "    # Save artifacts\n",
    "    pd.DataFrame(edges, columns=[\"u\", \"v\", \"length_km\"]).to_csv(edges_path, index=False)\n",
    "    A, C = edges_to_matrices(len(nodes), edges)\n",
    "    pd.DataFrame(A).to_csv(adj_path, index=False, header=False)\n",
    "    pd.DataFrame(C).to_csv(cost_path, index=False, header=False)\n",
    "    preview_segments(nodes, edges, preview_path, label_lengths=label_lengths)\n",
    "\n",
    "    meta = {\n",
    "        \"created_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"algorithm\": \"v1_greedy_mst\",\n",
    "        \"seed\": seed,\n",
    "        \"dataset_folder\": dataset_dir,\n",
    "        \"solution_dir\": sol_dir,\n",
    "        \"artifacts\": {\n",
    "            \"edges_csv\": edges_path,\n",
    "            \"adjacency_csv\": adj_path,\n",
    "            \"cost_csv\": cost_path,\n",
    "            \"preview_png\": preview_path,\n",
    "        },\n",
    "        \"n_nodes\": int(len(nodes)),\n",
    "        \"n_edges\": int(len(edges)),\n",
    "        \"total_length_km\": float(sum(w for _, _, w in edges)),\n",
    "    }\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    return {\"solution_dir\": sol_dir, \"edges\": edges_path, \"adjacency\": adj_path,\n",
    "            \"cost\": cost_path, \"preview\": preview_path, \"meta\": meta_path}\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Orchestration\n",
    "# ------------------------------\n",
    "def run_for_dataset(dataset_dir: str, cfg: SegV1Config) -> Dict[str, str] | None:\n",
    "    \"\"\"Create greedy MST solution for a single dataset folder (if missing).\"\"\"\n",
    "    nodes_csv = os.path.join(dataset_dir, \"nodes.csv\")\n",
    "    if not os.path.exists(nodes_csv):\n",
    "        return None\n",
    "\n",
    "    solution_name = cfg.solution_name or \"v1_greedy_mst\"\n",
    "    sol_dir = os.path.join(dataset_dir, cfg.solutions_subdir, solution_name)\n",
    "    if _solution_exists(sol_dir):\n",
    "        print(f\"[SKIP] Existing solution found → {sol_dir}\")\n",
    "        return None\n",
    "\n",
    "    # build solution\n",
    "    nodes = _load_nodes(nodes_csv)\n",
    "    D = _pairwise_distances(nodes[\"x_km\"].to_numpy(), nodes[\"y_km\"].to_numpy())\n",
    "    edges = build_mst_greedy_prim(D)\n",
    "    paths = write_solution(nodes, edges, dataset_dir, cfg.solutions_subdir, solution_name, cfg.label_lengths, cfg.seed)\n",
    "\n",
    "    print(f\"[OK]   Created solution → {paths['solution_dir']}\")\n",
    "    return paths\n",
    "\n",
    "\n",
    "def main(cfg: SegV1Config) -> List[Dict[str, str]]:\n",
    "    created: List[Dict[str, str]] = []\n",
    "\n",
    "    if cfg.dataset_root:\n",
    "        # Batch over every dataset under dataset_root\n",
    "        print(f\"Scanning datasets under: {cfg.dataset_root}\")\n",
    "        count = 0\n",
    "        for dataset_dir in _iter_datasets_with_nodes(cfg.dataset_root, cfg.solutions_subdir):\n",
    "            count += 1\n",
    "            out = run_for_dataset(dataset_dir, cfg)\n",
    "            if out:\n",
    "                created.append(out)\n",
    "        print(f\"\\n[Segments V1] Done. Datasets scanned: {count} | New solutions: {len(created)}\")\n",
    "        return created\n",
    "\n",
    "    # Single dataset mode\n",
    "    if not cfg.nodes_csv_path:\n",
    "        raise ValueError(\"Provide either dataset_root (batch) or nodes_csv_path (single).\")\n",
    "\n",
    "    dataset_dir = os.path.dirname(cfg.nodes_csv_path)\n",
    "    out = run_for_dataset(dataset_dir, cfg)\n",
    "    return [out] if out else []\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Run\n",
    "# ------------------------------\n",
    "_cfg = SegV1Config(\n",
    "    seed=42,\n",
    "    # Option A: run over ALL datasets\n",
    "    dataset_root=r\"C:\\Users\\User\\Documents\\Code\\traffic-optimization\\00_Datasets\",\n",
    "    # Option B: single dataset (leave dataset_root=None and set nodes_csv_path)\n",
    "    nodes_csv_path=None,  # r\"...\\some_dataset\\nodes.csv\"\n",
    "    solutions_subdir=\"solutions\",\n",
    "    solution_name=None,   # None → \"v1_greedy_mst\"\n",
    "    label_lengths=True,\n",
    ")\n",
    "\n",
    "_ = main(_cfg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
