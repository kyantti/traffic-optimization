{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afbd13b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building heatmap frames: 100%|██████████| 135/135 [00:24<00:00,  5.49it/s]\n",
      "Encoding MP4: 100%|██████████| 225/225 [00:04<00:00, 45.01it/s]\n",
      "Encoding GIF: 100%|██████████| 225/225 [00:01<00:00, 187.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 225 frames in: maps/sv1.2/dv0.1_v2_density_cities\\frames\n",
      "MP4: maps/sv1.2/dv0.1_v2_density_cities\\density_to_cities.mp4\n",
      "GIF: maps/sv1.2/dv0.1_v2_density_cities\\density_to_cities.gif\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Jupyter notebook cell — Version 2 (Nodes only)\n",
    "Population density → city nuclei via gravity-like clustering\n",
    "\n",
    "Goal: Start from a total population spread over space with higher/lower density areas,\n",
    "then let density peaks attract nearby population into city nuclei until only cities with\n",
    "≥ min_city_pop remain (e.g., 1,000 inhabitants).\n",
    "\n",
    "- Field: Mixture-of-Gaussians density + low‑frequency noise + uniform baseline\n",
    "- Allocation: Multinomial over grid cells (so total people is exact)\n",
    "- Peaks: Local maxima of the density with non‑maximum suppression (min separation)\n",
    "- Assignment: Each cell’s population goes to the peak with max attractiveness\n",
    "             A_j = weight_j / (distance + eps)^gamma, weight_j ∝ peak density\n",
    "- Pruning: Iteratively remove cities with pop < min_city_pop and reassign their cells\n",
    "- City center: Population‑weighted centroid of assigned cells\n",
    "- Outputs: nodes.csv, meta.json, preview.png (color = population; top‑3 annotated)\n",
    "\n",
    "Usage: run this cell. Edit `V2Config` at the end.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple, Dict, Any, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Config\n",
    "# ------------------------------\n",
    "@dataclass\n",
    "class V2Config:\n",
    "    seed: int = 42\n",
    "    total_population: int = 5_000_000\n",
    "    bbox_km: Tuple[float, float, float, float] = (0.0, 0.0, 200.0, 200.0)  # (minx, miny, maxx, maxy)\n",
    "\n",
    "    # Grid\n",
    "    grid_res_km: float = 2.0  # cell size (km). 200 km / 2 km ⇒ 100×100 grid\n",
    "\n",
    "    # Density mixture (centers auto if None)\n",
    "    n_centers: int = 4\n",
    "    center_sigma_km_min: float = 12.0\n",
    "    center_sigma_km_max: float = 35.0\n",
    "    baseline_frac: float = 0.05   # baseline level as a fraction of mean Gaussian field\n",
    "\n",
    "    # Low‑frequency noise (coarse grid upsampled bilinearly)\n",
    "    noise_amp: float = 0.30       # multiplicative amplitude; 0.3 ⇒ ×(1±0.3)\n",
    "    noise_grid: Tuple[int, int] = (10, 10)  # (rows, cols) of coarse noise grid\n",
    "\n",
    "    # Peak detection (on density field)\n",
    "    peaks_percentile: float = 92.0  # keep local maxima above this percentile\n",
    "    min_peak_separation_km: float = 8.0\n",
    "\n",
    "    # Gravity assignment\n",
    "    gamma: float = 1.7             # distance exponent in attractiveness\n",
    "    eps_km: float = 0.5            # small distance softening (km)\n",
    "\n",
    "    # City pruning\n",
    "    min_city_pop: int = 1_000\n",
    "\n",
    "    n_cities: int = 8                    # target minimum number of cities\n",
    "    peaks_percentile_floor: float = 60.0 # how far we can relax the threshold\n",
    "    separation_shrink: float = 0.85      # shrink factor for min peak separation per relax step\n",
    "    max_relax_iters: int = 10            # max relax attempts to reach n_cities\n",
    "\n",
    "\n",
    "    # Output & metadata\n",
    "    out_dir: str = \"maps/sv1.2/dv0.1_v2_density_cities\"\n",
    "    crs: str = \"EPSG:3857\"\n",
    "    schema_version: str = \"1.2\"  # optional new cols (`radius_km`, `n_cells_assigned`)\n",
    "    dataset_version: str = \"0.1\"\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Helpers\n",
    "# ------------------------------\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def _bbox_arrays(cfg: V2Config):\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "    W, H = maxx - minx, maxy - miny\n",
    "    nx = int(np.ceil(W / cfg.grid_res_km))\n",
    "    ny = int(np.ceil(H / cfg.grid_res_km))\n",
    "    x = minx + (np.arange(nx) + 0.5) * cfg.grid_res_km\n",
    "    y = miny + (np.arange(ny) + 0.5) * cfg.grid_res_km\n",
    "    X, Y = np.meshgrid(x, y)  # shape (ny, nx)\n",
    "    return X, Y, x, y, nx, ny\n",
    "\n",
    "\n",
    "def _dirichlet_weights(k: int) -> np.ndarray:\n",
    "    w = np.random.rand(k)\n",
    "    w = w + 0.01  # avoid zeros\n",
    "    return w / w.sum()\n",
    "\n",
    "\n",
    "def _upsample_bilinear(coarse: np.ndarray, ny: int, nx: int) -> np.ndarray:\n",
    "    \"\"\"Simple bilinear upsample using two 1D interpolations (no SciPy).\"\"\"\n",
    "    cy, cx = coarse.shape\n",
    "    x_old = np.linspace(0.0, 1.0, cx)\n",
    "    x_new = np.linspace(0.0, 1.0, nx)\n",
    "    # interp along x for each row\n",
    "    tmp = np.array([np.interp(x_new, x_old, coarse[i, :]) for i in range(cy)])  # (cy, nx)\n",
    "    y_old = np.linspace(0.0, 1.0, cy)\n",
    "    y_new = np.linspace(0.0, 1.0, ny)\n",
    "    # interp along y for each column\n",
    "    out = np.array([np.interp(y_new, y_old, tmp[:, j]) for j in range(nx)]).T  # (ny, nx)\n",
    "    return out\n",
    "\n",
    "\n",
    "def generate_density_field(cfg: V2Config) -> Tuple[np.ndarray, Dict[str, Any]]:\n",
    "    X, Y, x, y, nx, ny = _bbox_arrays(cfg)\n",
    "\n",
    "    # Mixture of Gaussians\n",
    "    centers = np.column_stack([\n",
    "        np.random.uniform(x.min(), x.max(), size=cfg.n_centers),\n",
    "        np.random.uniform(y.min(), y.max(), size=cfg.n_centers),\n",
    "    ])\n",
    "    sigmas = np.random.uniform(cfg.center_sigma_km_min, cfg.center_sigma_km_max, size=cfg.n_centers)\n",
    "    weights = _dirichlet_weights(cfg.n_centers)\n",
    "\n",
    "    G = np.zeros((ny, nx), dtype=float)\n",
    "    for (cx, cy), s, w in zip(centers, sigmas, weights):\n",
    "        G += w * np.exp(-((X - cx) ** 2 + (Y - cy) ** 2) / (2 * s * s))\n",
    "\n",
    "    # Baseline\n",
    "    baseline = cfg.baseline_frac * (G.mean() + 1e-9)\n",
    "\n",
    "    # Low-frequency noise\n",
    "    if cfg.noise_amp > 0:\n",
    "        ngy, ngx = cfg.noise_grid\n",
    "        coarse = np.random.rand(ngy, ngx)\n",
    "        noise = _upsample_bilinear(coarse, ny, nx)\n",
    "        noise = (noise - 0.5) * 2.0  # ~[-1,1]\n",
    "        field = (G + baseline) * (1.0 + cfg.noise_amp * noise)\n",
    "        field = np.clip(field, a_min=baseline * 0.1, a_max=None)\n",
    "    else:\n",
    "        field = G + baseline\n",
    "\n",
    "    info = {\n",
    "        \"centers\": centers.tolist(),\n",
    "        \"sigmas\": sigmas.tolist(),\n",
    "        \"weights\": weights.tolist(),\n",
    "        \"baseline\": baseline,\n",
    "        \"noise_amp\": cfg.noise_amp,\n",
    "        \"noise_grid\": cfg.noise_grid,\n",
    "    }\n",
    "    return field, info\n",
    "\n",
    "\n",
    "def _find_local_maxima(field: np.ndarray, percentile: float, min_sep_cells: int) -> List[Tuple[int, int, float]]:\n",
    "    ny, nx = field.shape\n",
    "    thr = np.percentile(field, percentile)\n",
    "    peaks: List[Tuple[int, int, float]] = []\n",
    "    for i in range(1, ny - 1):\n",
    "        for j in range(1, nx - 1):\n",
    "            v = field[i, j]\n",
    "            if v < thr:\n",
    "                continue\n",
    "            nb = field[i-1:i+2, j-1:j+2]\n",
    "            if v >= nb.max():\n",
    "                peaks.append((i, j, float(v)))\n",
    "    # Non-maximum suppression by min_sep_cells (greedy)\n",
    "    peaks.sort(key=lambda t: t[2], reverse=True)\n",
    "    accepted: List[Tuple[int, int, float]] = []\n",
    "    for i, j, v in peaks:\n",
    "        ok = True\n",
    "        for ia, ja, _ in accepted:\n",
    "            if (i - ia) ** 2 + (j - ja) ** 2 < (min_sep_cells ** 2):\n",
    "                ok = False\n",
    "                break\n",
    "        if ok:\n",
    "            accepted.append((i, j, v))\n",
    "    return accepted\n",
    "\n",
    "\n",
    "def _assign_cells_to_peaks(counts: np.ndarray, field: np.ndarray, peaks: List[Tuple[int, int, float]], cfg: V2Config) -> np.ndarray:\n",
    "    \"\"\"Return array of shape (ny, nx) with city index per cell (−1 if no peaks).\"\"\"\n",
    "    ny, nx = counts.shape\n",
    "    if not peaks:\n",
    "        return -np.ones((ny, nx), dtype=int)\n",
    "\n",
    "    # Precompute peak weights and coordinates in km\n",
    "    X, Y, x, y, nx2, ny2 = _bbox_arrays(cfg)\n",
    "    assert nx2 == nx and ny2 == ny\n",
    "\n",
    "    px = np.array([x[int(j)] for (_, j, _) in peaks])  # careful: peaks store (row=i, col=j)\n",
    "    py = np.array([y[int(i)] for (i, _, _) in peaks])\n",
    "\n",
    "    peak_weight = np.array([v for (_, _, v) in peaks], dtype=float)\n",
    "    peak_weight = peak_weight / (peak_weight.max() + 1e-12)\n",
    "\n",
    "    # We compute attractiveness for each peak: w / (dist + eps)^gamma\n",
    "    eps2 = (cfg.eps_km ** 2)\n",
    "\n",
    "    # Flatten coordinates for vectorization\n",
    "    XX = X.reshape(-1)\n",
    "    YY = Y.reshape(-1)\n",
    "    counts_flat = counts.reshape(-1)\n",
    "\n",
    "    # Only consider cells with people\n",
    "    active_idx = np.where(counts_flat > 0)[0]\n",
    "    XXa = XX[active_idx][:, None]\n",
    "    YYa = YY[active_idx][:, None]\n",
    "\n",
    "    # distances to peaks (active cells × n_peaks)\n",
    "    dx = XXa - px[None, :]\n",
    "    dy = YYa - py[None, :]\n",
    "    dist2 = dx * dx + dy * dy\n",
    "\n",
    "    attractiveness = peak_weight[None, :] / np.power(dist2 + eps2, cfg.gamma / 2.0)\n",
    "    best = np.argmax(attractiveness, axis=1)\n",
    "\n",
    "    assign = -np.ones(XX.shape[0], dtype=int)\n",
    "    assign[active_idx] = best\n",
    "    return assign.reshape(ny, nx)\n",
    "\n",
    "\n",
    "def _city_stats_from_assignment(assign: np.ndarray, counts: np.ndarray, cfg: V2Config) -> Tuple[pd.DataFrame, Dict[int, np.ndarray]]:\n",
    "    \"\"\"Compute city populations, centroids, radius, and keep cell masks per city.\"\"\"\n",
    "    X, Y, *_ = _bbox_arrays(cfg)\n",
    "    ny, nx = counts.shape\n",
    "\n",
    "    city_ids = np.unique(assign[assign >= 0])\n",
    "    masks: Dict[int, np.ndarray] = {}\n",
    "    rows = []\n",
    "    for cid in city_ids:\n",
    "        mask = assign == cid\n",
    "        pop = int(counts[mask].sum())\n",
    "        if pop <= 0:\n",
    "            continue\n",
    "        masks[cid] = mask\n",
    "        # Pop-weighted centroid\n",
    "        w = counts[mask].astype(float)\n",
    "        xs = X[mask]\n",
    "        ys = Y[mask]\n",
    "        x_c = float((w * xs).sum() / w.sum())\n",
    "        y_c = float((w * ys).sum() / w.sum())\n",
    "        n_cells = int(mask.sum())\n",
    "        area_km2 = n_cells * (cfg.grid_res_km ** 2)\n",
    "        radius_km = float(np.sqrt(area_km2 / np.pi))\n",
    "        rows.append({\"city_id\": int(cid), \"x_km\": x_c, \"y_km\": y_c, \"pop\": pop, \"n_cells_assigned\": n_cells, \"radius_km\": radius_km})\n",
    "\n",
    "    df = pd.DataFrame(rows).sort_values(\"pop\", ascending=False).reset_index(drop=True)\n",
    "    return df, masks\n",
    "\n",
    "\n",
    "def _prune_and_reassign(assign: np.ndarray, counts: np.ndarray, peaks: List[Tuple[int, int, float]], cfg: V2Config) -> Tuple[np.ndarray, List[int]]:\n",
    "    \"\"\"Iteratively remove cities below threshold and reassign their cells to survivors.\"\"\"\n",
    "    ny, nx = counts.shape\n",
    "    while True:\n",
    "        df, masks = _city_stats_from_assignment(assign, counts, cfg)\n",
    "        if df.empty:\n",
    "            raise RuntimeError(\"No cities formed — check parameters.\")\n",
    "        low = df[df[\"pop\"] < cfg.min_city_pop]\n",
    "        if low.empty or len(df) == 1:\n",
    "            # Done\n",
    "            survivors = df[\"city_id\"].tolist()\n",
    "            return assign, survivors\n",
    "        # Remove the smallest city under threshold\n",
    "        remove_id = int(low.sort_values(\"pop\").iloc[0][\"city_id\"])\n",
    "        # Reassign its cells to the best among survivors\n",
    "        survivors = [int(cid) for cid in df[\"city_id\"].tolist() if cid != remove_id]\n",
    "\n",
    "        # Build survivors peak subset\n",
    "        surv_peaks = [peaks[cid] for cid in survivors]\n",
    "        # Temporarily set these cells to -1 to be reassigned\n",
    "        rem_mask = masks[remove_id]\n",
    "        assign[rem_mask] = -1\n",
    "\n",
    "        # Reassign only the removed cells by recomputing best survivor for those cells\n",
    "        # Compute attractiveness for survivors\n",
    "        X, Y, x, y, nx2, ny2 = _bbox_arrays(cfg)\n",
    "        px = np.array([x[int(j)] for (i, j, v) in surv_peaks])\n",
    "        py = np.array([y[int(i)] for (i, j, v) in surv_peaks])\n",
    "        peak_weight = np.array([v for (i, j, v) in surv_peaks], dtype=float)\n",
    "        peak_weight = peak_weight / (peak_weight.max() + 1e-12)\n",
    "        eps2 = (cfg.eps_km ** 2)\n",
    "\n",
    "        idx_cells = np.where(rem_mask.reshape(-1))[0]\n",
    "        XX = X.reshape(-1)[idx_cells][:, None]\n",
    "        YY = Y.reshape(-1)[idx_cells][:, None]\n",
    "        dx = XX - px[None, :]\n",
    "        dy = YY - py[None, :]\n",
    "        dist2 = dx * dx + dy * dy\n",
    "        attractiveness = peak_weight[None, :] / np.power(dist2 + eps2, cfg.gamma / 2.0)\n",
    "        best = np.argmax(attractiveness, axis=1)\n",
    "        reassigned = np.array([survivors[b] for b in best], dtype=int)\n",
    "\n",
    "        # Write back\n",
    "        flat_assign = assign.reshape(-1)\n",
    "        flat_assign[idx_cells] = reassigned\n",
    "        assign = flat_assign.reshape(ny, nx)\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Main generator / validator / saver\n",
    "# ------------------------------\n",
    "\n",
    "def generate_nodes_v2(cfg: V2Config) -> Tuple[pd.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Guarantee >= cfg.n_cities with each city >= cfg.min_city_pop by:\n",
    "      1) detecting density peaks (relaxing thresholds if needed),\n",
    "      2) assigning by gravity,\n",
    "      3) pruning tiny cities,\n",
    "      4) if still short, SPLITTING the largest city into two (by weighted median along the widest axis)\n",
    "         and repeating assignment until the target count is reached or no city can be split further.\n",
    "    \"\"\"\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    # ----- Density + allocation -----\n",
    "    field, field_info = generate_density_field(cfg)\n",
    "    probs = field / field.sum()\n",
    "    X, Y, x, y, nx, ny = _bbox_arrays(cfg)\n",
    "    counts = np.random.multinomial(cfg.total_population, probs.reshape(-1)).reshape(ny, nx)\n",
    "\n",
    "    def find_peaks(percentile: float, sep_cells: int) -> List[Tuple[int, int, float]]:\n",
    "        return _find_local_maxima(field, percentile, max(1, sep_cells))\n",
    "\n",
    "    def assign_and_stats(peaks: List[Tuple[int, int, float]]):\n",
    "        assign = _assign_cells_to_peaks(counts, field, peaks, cfg)\n",
    "        df_cities, masks = _city_stats_from_assignment(assign, counts, cfg)\n",
    "        return assign, df_cities, masks\n",
    "\n",
    "    def prune_below_threshold(assign: np.ndarray, peaks: List[Tuple[int, int, float]]):\n",
    "        # use existing prune (merges tiny cities into survivors)\n",
    "        assign2, survivors = _prune_and_reassign(assign.copy(), counts, peaks, cfg)\n",
    "        df2, masks2 = _city_stats_from_assignment(assign2, counts, cfg)\n",
    "        return assign2, df2, masks2\n",
    "\n",
    "    def split_city_mask(mask: np.ndarray) -> List[Tuple[int, int, float]] | None:\n",
    "        \"\"\"Split one city into two by weighted median along widest axis; return two new peak tuples (i,j,value).\"\"\"\n",
    "        w = counts[mask].astype(float)\n",
    "        if w.sum() < 2 * cfg.min_city_pop or mask.sum() < 2:\n",
    "            return None\n",
    "        xs = X[mask]; ys = Y[mask]\n",
    "        # choose axis with larger variance\n",
    "        varx, vary = np.var(xs, ddof=0), np.var(ys, ddof=0)\n",
    "        coord = xs if varx >= vary else ys\n",
    "        order = np.argsort(coord)\n",
    "        w_sorted = w[order]\n",
    "        xs_sorted, ys_sorted = xs[order], ys[order]\n",
    "        csum = np.cumsum(w_sorted)\n",
    "        # cut near half but ensure both sides >= min_city_pop\n",
    "        total = csum[-1]\n",
    "        cut_idx = np.searchsorted(csum, total / 2.0)\n",
    "        # expand cut to meet threshold\n",
    "        left_ok = lambda k: csum[k] >= cfg.min_city_pop\n",
    "        right_ok = lambda k: (total - csum[k]) >= cfg.min_city_pop\n",
    "        k = int(np.clip(cut_idx, 1, len(w_sorted) - 2))\n",
    "        moved = True\n",
    "        while moved:\n",
    "            moved = False\n",
    "            if not left_ok(k):\n",
    "                k += 1; moved = True\n",
    "            if not right_ok(k):\n",
    "                k -= 1; moved = True\n",
    "            if k <= 0 or k >= len(w_sorted) - 1:\n",
    "                return None  # cannot split with thresholds\n",
    "        # weighted centroids for two parts\n",
    "        wL, wR = w_sorted[:k], w_sorted[k:]\n",
    "        xL = float(np.average(xs_sorted[:k], weights=wL))\n",
    "        yL = float(np.average(ys_sorted[:k], weights=wL))\n",
    "        xR = float(np.average(xs_sorted[k:],  weights=wR))\n",
    "        yR = float(np.average(ys_sorted[k:],  weights=wR))\n",
    "        # snap to nearest grid cells\n",
    "        jL, iL = int(np.argmin(np.abs(x - xL))), int(np.argmin(np.abs(y - yL)))\n",
    "        jR, iR = int(np.argmin(np.abs(x - xR))), int(np.argmin(np.abs(y - yR)))\n",
    "        pL = (iL, jL, float(field[iL, jL]))\n",
    "        pR = (iR, jR, float(field[iR, jR]))\n",
    "        return [pL, pR]\n",
    "\n",
    "    # ---- 1) initial peaks with relaxation ----\n",
    "    current_pct = float(getattr(cfg, \"peaks_percentile\", 92.0))\n",
    "    current_sep = int(round(cfg.min_peak_separation_km / cfg.grid_res_km))\n",
    "    pct_floor = float(getattr(cfg, \"peaks_percentile_floor\", 60.0))\n",
    "    shrink = float(getattr(cfg, \"separation_shrink\", 0.85))\n",
    "    max_relax = int(getattr(cfg, \"max_relax_iters\", 10))\n",
    "\n",
    "    peaks = find_peaks(current_pct, current_sep)\n",
    "    for _ in range(max_relax):\n",
    "        assign, df, masks = assign_and_stats(peaks)\n",
    "        # prune tiny cities (merge) only if we still have >= n_cities afterwards\n",
    "        assign_p, df_p, masks_p = prune_below_threshold(assign, peaks)\n",
    "        df = df_p; masks = masks_p; assign = assign_p\n",
    "        if len(df) >= cfg.n_cities:\n",
    "            break\n",
    "        # relax detection if we can\n",
    "        new_pct = max(pct_floor, current_pct - 5.0)\n",
    "        new_sep = max(1, int(np.ceil(current_sep * shrink)))\n",
    "        new_peaks = find_peaks(new_pct, new_sep)\n",
    "        if len(new_peaks) > len(peaks):  # only accept if we actually got more\n",
    "            peaks, current_pct, current_sep = new_peaks, new_pct, new_sep\n",
    "        else:\n",
    "            break  # no further improvement\n",
    "\n",
    "    # ---- 2) enforce minimum by splitting largest cities if needed ----\n",
    "    # always recompute with current peaks\n",
    "    assign, df, masks = assign_and_stats(peaks)\n",
    "    # prune tiny ones first (merge them up)\n",
    "    assign, df, masks = prune_below_threshold(assign, peaks)\n",
    "\n",
    "    # if still short, repeatedly split the largest splittable city\n",
    "    attempts = 0\n",
    "    while len(df) < cfg.n_cities:\n",
    "        attempts += 1\n",
    "        if attempts > 200:  # safety\n",
    "            break\n",
    "        # pick largest city that can be split\n",
    "        df_sorted = df.sort_values(\"pop\", ascending=False)\n",
    "        split_done = False\n",
    "        for _, row in df_sorted.iterrows():\n",
    "            cid = int(row[\"city_id\"])\n",
    "            mask = masks[cid]\n",
    "            new_two = split_city_mask(mask)\n",
    "            if new_two is None:\n",
    "                continue\n",
    "            # replace this city's peak with two new peaks\n",
    "            peaks = [p for idx, p in enumerate(peaks) if idx != cid] + new_two\n",
    "            # reassign & prune\n",
    "            assign, df, masks = assign_and_stats(peaks)\n",
    "            assign, df, masks = prune_below_threshold(assign, peaks)\n",
    "            split_done = True\n",
    "            if len(df) >= cfg.n_cities:\n",
    "                break\n",
    "        if not split_done:\n",
    "            break  # no city can be split further while respecting min_city_pop\n",
    "\n",
    "    if len(df) < cfg.n_cities:\n",
    "        raise RuntimeError(f\"Could not reach the target number of cities (got {len(df)}, want {cfg.n_cities}). \"\n",
    "                           f\"Try decreasing min_city_pop, increasing total_population, or using finer grid_res_km.\")\n",
    "\n",
    "    # ---- finalize nodes ----\n",
    "    df_cities = df\n",
    "    assert int(df_cities[\"pop\"].sum()) == int(cfg.total_population)\n",
    "\n",
    "    df_nodes = df_cities.rename(columns={\"city_id\": \"id\"})[\n",
    "        [\"id\", \"x_km\", \"y_km\", \"pop\", \"n_cells_assigned\", \"radius_km\"]\n",
    "    ].copy()\n",
    "    df_nodes[\"id\"] = df_nodes[\"id\"].astype(int)\n",
    "\n",
    "    extras = {\n",
    "        \"grid\": {\"nx\": nx, \"ny\": ny, \"res_km\": cfg.grid_res_km},\n",
    "        \"peaks_count_used\": int(len(peaks)),\n",
    "        \"relaxation\": {\n",
    "            \"final_percentile\": current_pct,\n",
    "            \"final_sep_cells\": current_sep,\n",
    "            \"target_n_cities\": int(cfg.n_cities),\n",
    "            \"achieved_n_cities\": int(len(df_nodes)),\n",
    "        },\n",
    "        \"field_info\": field_info,\n",
    "        \"counts\": counts,\n",
    "        \"field\": field,\n",
    "    }\n",
    "    return df_nodes, extras\n",
    "\n",
    "def validate_nodes(df_nodes: pd.DataFrame, cfg: V2Config) -> Dict[str, Any]:\n",
    "    metrics: Dict[str, Any] = {}\n",
    "    n = len(df_nodes)\n",
    "    if n == 0:\n",
    "        raise AssertionError(\"No cities produced\")\n",
    "    if (df_nodes[\"pop\"] < cfg.min_city_pop).any():\n",
    "        raise AssertionError(\"Found a city below min_city_pop after pruning\")\n",
    "    metrics[\"n_cities\"] = int(n)\n",
    "    metrics[\"total_population\"] = int(df_nodes[\"pop\"].sum())\n",
    "    metrics[\"pop_percentiles\"] = {q: int(np.percentile(df_nodes[\"pop\"], q)) for q in (5, 25, 50, 75, 90, 95, 99)}\n",
    "    return metrics\n",
    "\n",
    "def preview_nodes(df_nodes: pd.DataFrame, cfg: V2Config, save_path: str) -> None:\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    vmax = df_nodes[\"pop\"].max()\n",
    "    sc = plt.scatter(\n",
    "        df_nodes[\"x_km\"], df_nodes[\"y_km\"],\n",
    "        s=10 + 90 * np.sqrt(df_nodes[\"pop\"].values / vmax),\n",
    "        c=df_nodes[\"pop\"].values.astype(float),\n",
    "    )\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"Population\")\n",
    "    try:\n",
    "        cbar.ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Annotate top‑3 by population\n",
    "    top3 = df_nodes.nlargest(3, \"pop\").copy()\n",
    "    dx = 0.01 * (maxx - minx)\n",
    "    dy = 0.01 * (maxy - miny)\n",
    "    for _, row in top3.iterrows():\n",
    "        label = f\"{int(row['pop']):,}\"\n",
    "        plt.text(\n",
    "            row[\"x_km\"] + dx,\n",
    "            row[\"y_km\"] + dy,\n",
    "            label,\n",
    "            fontsize=8,\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "        )\n",
    "\n",
    "    plt.title(\"Nodes — V2 (density → gravity cities)\")\n",
    "    plt.xlabel(\"x (km)\")\n",
    "    plt.ylabel(\"y (km)\")\n",
    "    plt.xlim(minx, maxx)\n",
    "    plt.ylim(miny, maxy)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def compute_metrics_hash(metrics: Dict[str, Any]) -> str:\n",
    "    blob = json.dumps(metrics, sort_keys=True).encode(\"utf-8\")\n",
    "    return hashlib.sha256(blob).hexdigest()[:16]\n",
    "\n",
    "def save_artifacts(df_nodes: pd.DataFrame, cfg: V2Config, metrics: Dict[str, Any], extras: Dict[str, Any]) -> Dict[str, str]:\n",
    "    import matplotlib.pyplot as plt\n",
    "    from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "    nodes_path = os.path.join(cfg.out_dir, \"nodes.csv\")\n",
    "    preview_path = os.path.join(cfg.out_dir, \"preview.png\")\n",
    "    heatmap_path = os.path.join(cfg.out_dir, \"population_heatmap.png\")\n",
    "    meta_path = os.path.join(cfg.out_dir, \"meta.json\")\n",
    "\n",
    "    # Save nodes CSV\n",
    "    df_nodes.to_csv(nodes_path, index=False)\n",
    "\n",
    "    # Existing scatter preview of cities\n",
    "    preview_nodes(df_nodes, cfg, preview_path)\n",
    "\n",
    "    # --- NEW: heatmap of individual distribution (grid cell counts) ---\n",
    "    counts = extras.get(\"counts\", None)  # expected shape (ny, nx)\n",
    "    if counts is not None:\n",
    "        minx, miny, maxx, maxy = cfg.bbox_km\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        # imshow with spatial extent to align axes with km coordinates\n",
    "        plt.imshow(\n",
    "            counts,\n",
    "            origin=\"lower\",\n",
    "            extent=[minx, maxx, miny, maxy],\n",
    "            aspect=\"equal\",\n",
    "        )\n",
    "        cbar = plt.colorbar()\n",
    "        cbar.set_label(\"People per cell\")\n",
    "        try:\n",
    "            cbar.ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "        except Exception:\n",
    "            pass\n",
    "        plt.title(\"Population distribution (heatmap)\")\n",
    "        plt.xlabel(\"x (km)\")\n",
    "        plt.ylabel(\"y (km)\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(heatmap_path, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "    # Meta\n",
    "    meta = {\n",
    "        \"schema_version\": cfg.schema_version,\n",
    "        \"dataset_version\": cfg.dataset_version,\n",
    "        \"crs\": cfg.crs,\n",
    "        \"seed\": cfg.seed,\n",
    "        \"generator\": {\n",
    "            \"name\": \"nodes_v2_density_to_cities\",\n",
    "            \"params\": {\n",
    "                \"total_population\": cfg.total_population,\n",
    "                \"bbox_km\": cfg.bbox_km,\n",
    "                \"grid_res_km\": cfg.grid_res_km,\n",
    "                \"n_centers\": cfg.n_centers,\n",
    "                \"center_sigma_km_min\": cfg.center_sigma_km_min,\n",
    "                \"center_sigma_km_max\": cfg.center_sigma_km_max,\n",
    "                \"baseline_frac\": cfg.baseline_frac,\n",
    "                \"noise_amp\": cfg.noise_amp,\n",
    "                \"noise_grid\": cfg.noise_grid,\n",
    "                \"peaks_percentile\": cfg.peaks_percentile,\n",
    "                \"min_peak_separation_km\": cfg.min_peak_separation_km,\n",
    "                \"gamma\": cfg.gamma,\n",
    "                \"eps_km\": cfg.eps_km,\n",
    "                \"min_city_pop\": cfg.min_city_pop,\n",
    "            },\n",
    "        },\n",
    "        \"extras_summary\": {\n",
    "            \"grid\": extras.get(\"grid\"),\n",
    "            \"peaks_count\": extras.get(\"peaks_count\"),\n",
    "        },\n",
    "        \"artifacts\": {\n",
    "            \"nodes_csv\": nodes_path,\n",
    "            \"preview_png\": preview_path,\n",
    "            \"population_heatmap_png\": heatmap_path if counts is not None else None,\n",
    "        },\n",
    "        \"metrics\": metrics,\n",
    "        \"metrics_hash\": compute_metrics_hash(metrics),\n",
    "        \"created_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    }\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    return {\"nodes\": nodes_path, \"preview\": preview_path, \"heatmap\": (heatmap_path if counts is not None else None), \"meta\": meta_path}\n",
    "\n",
    "# ------------------------------\n",
    "# Orchestration\n",
    "# ------------------------------\n",
    "\n",
    "def main(cfg: V2Config | None = None) -> pd.DataFrame:\n",
    "    cfg = cfg or V2Config()\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    df_nodes, extras = generate_nodes_v2(cfg)\n",
    "    metrics = validate_nodes(df_nodes, cfg)\n",
    "    paths = save_artifacts(df_nodes, cfg, metrics, extras)\n",
    "\n",
    "    print(\"\\n[Nodes V2] Build complete:\\n\" + \"-\" * 40)\n",
    "    print(f\"Cities: {len(df_nodes)} | Total pop: {metrics['total_population']:,}\")\n",
    "    print(f\"Saved: nodes → {paths['nodes']}\\n       preview → {paths['preview']}\\n       meta → {paths['meta']}\")\n",
    "    print(f\"Metrics hash: {compute_metrics_hash(metrics)}\")\n",
    "    return df_nodes\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Run\n",
    "# ------------------------------\n",
    "_cfg = V2Config(\n",
    "    seed=42,\n",
    "    total_population=5_000_000,\n",
    "    bbox_km=(0.0, 0.0, 200.0, 200.0),\n",
    "    grid_res_km=2.0,\n",
    "    n_centers=4,\n",
    "    center_sigma_km_min=12.0,\n",
    "    center_sigma_km_max=35.0,\n",
    "    baseline_frac=0.05,\n",
    "    noise_amp=0.30,\n",
    "    noise_grid=(10, 10),\n",
    "    peaks_percentile=92.0,\n",
    "    min_peak_separation_km=8.0,\n",
    "    gamma=1.7,\n",
    "    eps_km=0.5,\n",
    "    min_city_pop=1_000,\n",
    "    n_cities=20,\n",
    "    peaks_percentile_floor=60.0,\n",
    "    separation_shrink=0.85,\n",
    "    max_relax_iters=10,\n",
    "    out_dir=\"maps/sv1.2/dv0.1_v2_density_cities\",\n",
    ")\n",
    "\n",
    "# Jupyter notebook cell — Animation builder (≤ 15s)\n",
    "# Requires: matplotlib, numpy, pandas, tqdm, opencv-python (for MP4), imageio (optional for GIF)\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, math, gc\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Optional encoders\n",
    "try:\n",
    "    import cv2  # for MP4\n",
    "    _HAS_CV2 = True\n",
    "except Exception:\n",
    "    _HAS_CV2 = False\n",
    "\n",
    "try:\n",
    "    import imageio.v2 as imageio  # for GIF (optional)\n",
    "    _HAS_IMAGEIO = True\n",
    "except Exception:\n",
    "    _HAS_IMAGEIO = False\n",
    "\n",
    "\n",
    "def _ease_in_out(t: np.ndarray, power: float = 2.0) -> np.ndarray:\n",
    "    \"\"\"Smooth easing 0→1 (s-curve).\"\"\"\n",
    "    t = np.clip(t, 0.0, 1.0)\n",
    "    a = np.power(t, power) / (np.power(t, power) + np.power(1 - t, power))\n",
    "    a[np.isnan(a)] = 0.0\n",
    "    return a\n",
    "\n",
    "\n",
    "def _plot_heatmap(counts: np.ndarray, cfg: V2Config, save_path: str,\n",
    "                  vmin=None, vmax=None) -> None:\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    im = plt.imshow(\n",
    "        counts, origin=\"lower\",\n",
    "        extent=[minx, maxx, miny, maxy], aspect=\"equal\",\n",
    "        vmin=vmin, vmax=vmax, cmap=\"viridis\"\n",
    "    )\n",
    "    cbar = plt.colorbar(im)\n",
    "    cbar.set_label(\"People per cell\")\n",
    "    try:\n",
    "        cbar.ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    except Exception:\n",
    "        pass\n",
    "    plt.title(\"Population distribution (heatmap)\")\n",
    "    plt.xlabel(\"x (km)\")\n",
    "    plt.ylabel(\"y (km)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# --- UPDATED helpers ---\n",
    "\n",
    "def _plot_scatter(df_nodes: pd.DataFrame, cfg: V2Config, save_path: str,\n",
    "                  grow: float = 1.0,\n",
    "                  heatmap_underlay: np.ndarray | None = None,\n",
    "                  heatmap_vmin: float | None = None,\n",
    "                  heatmap_vmax: float | None = None,\n",
    "                  heatmap_alpha: float = 0.25) -> None:\n",
    "    \"\"\"\n",
    "    Scatter of cities; if heatmap_underlay is provided, draw it underneath\n",
    "    with given alpha (default 0.25) so we see density + cities together.\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    # Optional heatmap underlay\n",
    "    if heatmap_underlay is not None:\n",
    "        plt.imshow(\n",
    "            heatmap_underlay,\n",
    "            origin=\"lower\",\n",
    "            extent=[minx, maxx, miny, maxy],\n",
    "            aspect=\"equal\",\n",
    "            cmap=\"viridis\",\n",
    "            vmin=heatmap_vmin, vmax=heatmap_vmax,\n",
    "            alpha=heatmap_alpha,\n",
    "            zorder=0\n",
    "        )\n",
    "\n",
    "    # Cities on top\n",
    "    vmax = df_nodes[\"pop\"].max()\n",
    "    sizes = (10 + 90 * np.sqrt(df_nodes[\"pop\"].values / vmax)) * np.clip(grow, 0.05, 1.0)\n",
    "    sc = plt.scatter(\n",
    "        df_nodes[\"x_km\"], df_nodes[\"y_km\"],\n",
    "        s=sizes, c=df_nodes[\"pop\"].values.astype(float),\n",
    "        cmap=\"viridis\", zorder=1\n",
    "    )\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"Population\")\n",
    "    try:\n",
    "        cbar.ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    # Labels near the end\n",
    "    if grow >= 0.85:\n",
    "        top3 = df_nodes.nlargest(3, \"pop\").copy()\n",
    "        dx = 0.01 * (maxx - minx)\n",
    "        dy = 0.01 * (maxy - miny)\n",
    "        for _, row in top3.iterrows():\n",
    "            label = f\"{int(row['pop']):,}\"\n",
    "            plt.text(row[\"x_km\"] + dx, row[\"y_km\"] + dy, label,\n",
    "                     fontsize=8, ha=\"left\", va=\"bottom\",\n",
    "                     bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "                     zorder=2)\n",
    "\n",
    "    plt.title(\"Nodes — V2 (density → gravity cities)\")\n",
    "    plt.xlabel(\"x (km)\"); plt.ylabel(\"y (km)\")\n",
    "    plt.xlim(minx, maxx); plt.ylim(miny, maxy)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "def make_frames_density_to_cities(cfg: V2Config,\n",
    "                                  total_duration_s: float = 15.0,\n",
    "                                  fps: int = 15,\n",
    "                                  frames_dir_name: str = \"frames\",\n",
    "                                  also_gif: bool = False) -> Tuple[List[str], str, str]:\n",
    "    \"\"\"\n",
    "    Generates frames for:\n",
    "      1) Heatmap build (ends exactly at the full heatmap)\n",
    "      2) Node scatter growth (ends exactly at final preview)\n",
    "    Returns (frame_paths, mp4_path, gif_path_or_None).\n",
    "    \"\"\"\n",
    "    # --- Generate the data (deterministic due to cfg.seed) ---\n",
    "    df_nodes, extras = generate_nodes_v2(cfg)\n",
    "    counts = extras[\"counts\"]  # (ny, nx)\n",
    "\n",
    "    vmin, vmax = np.min(counts), np.max(counts)\n",
    "\n",
    "    # Where to save things\n",
    "    out_dir = cfg.out_dir\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    frames_dir = os.path.join(out_dir, frames_dir_name)\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "    # Timing and partition (≈60% heatmap, 40% scatter)\n",
    "    total_frames = max(1, int(min(total_duration_s, 15.0) * fps))\n",
    "    n_heat = max(8, int(total_frames * 0.6))\n",
    "    n_scatter = max(8, total_frames - n_heat)\n",
    "\n",
    "    # Fix color scaling so the first part ends matching your heatmap asset\n",
    "    vmin, vmax = np.min(counts), np.max(counts)\n",
    "\n",
    "    paths: List[str] = []\n",
    "    fidx = 0\n",
    "\n",
    "    # ---------- Stage 1: heatmap build ----------\n",
    "    t_heat = _ease_in_out(np.linspace(0.0, 1.0, n_heat), power=2.5)\n",
    "    for r in tqdm(t_heat, total=n_heat, desc=\"Building heatmap frames\"):\n",
    "        # cumulative reveal (monotone increase) using easing ratio\n",
    "        partial = np.floor(counts * r).astype(counts.dtype)\n",
    "        frame_path = os.path.join(frames_dir, f\"frame_{fidx:04d}.png\")\n",
    "        _plot_heatmap(partial, cfg, frame_path, vmin=vmin, vmax=vmax)\n",
    "        paths.append(frame_path)\n",
    "        fidx += 1\n",
    "\n",
    "    # ---------- Stage 2: nodes growth ----------\n",
    "    t_sc = _ease_in_out(np.linspace(0.0, 1.0, n_scatter), power=2.0)\n",
    "\n",
    "    # If you ever want the very last frame WITHOUT the underlay (to match your old second image),\n",
    "    # set overlay_in_final = False.\n",
    "    overlay_in_final = True\n",
    "\n",
    "    for k, g in enumerate(t_sc):\n",
    "        use_underlay = counts if (overlay_in_final or k < len(t_sc) - 1) else None\n",
    "        frame_path = os.path.join(frames_dir, f\"frame_{fidx:04d}.png\")\n",
    "        _plot_scatter(\n",
    "            df_nodes, cfg, frame_path,\n",
    "            grow=float(g),\n",
    "            heatmap_underlay=use_underlay,\n",
    "            heatmap_vmin=vmin, heatmap_vmax=vmax,\n",
    "            heatmap_alpha=0.66\n",
    "        )\n",
    "        paths.append(frame_path)\n",
    "        fidx += 1\n",
    "\n",
    "    # ---------- Encode MP4 (always) ----------\n",
    "    mp4_path = os.path.join(out_dir, \"density_to_cities.mp4\")\n",
    "    if not _HAS_CV2:\n",
    "        raise RuntimeError(\"opencv-python is required to generate MP4. Install with: pip install opencv-python\")\n",
    "\n",
    "    # Get frame size from first image\n",
    "    first = cv2.imread(paths[0])\n",
    "    if first is None:\n",
    "        raise RuntimeError(\"Failed to read first frame for video encoding.\")\n",
    "    h, w = first.shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "    writer = cv2.VideoWriter(mp4_path, fourcc, fps, (w, h))\n",
    "    if not writer.isOpened():\n",
    "        raise RuntimeError(\"Failed to open VideoWriter. Check OpenCV codecs.\")\n",
    "\n",
    "    for p in tqdm(paths, desc=\"Encoding MP4\"):\n",
    "        img = cv2.imread(p)\n",
    "        if img is None:\n",
    "            continue\n",
    "        # Ensure size matches exactly\n",
    "        if img.shape[1] != w or img.shape[0] != h:\n",
    "            img = cv2.resize(img, (w, h), interpolation=cv2.INTER_AREA)\n",
    "        writer.write(img)\n",
    "    writer.release()\n",
    "\n",
    "    # ---------- Optional GIF ----------\n",
    "    gif_path = None\n",
    "    if also_gif and _HAS_IMAGEIO:\n",
    "        gif_path = os.path.join(out_dir, \"density_to_cities.gif\")\n",
    "        imgs = [imageio.imread(p) for p in tqdm(paths, desc=\"Encoding GIF\")]\n",
    "        # duration per frame in seconds\n",
    "        imageio.mimsave(gif_path, imgs, duration=1.0 / fps)\n",
    "\n",
    "    # Clean up big arrays\n",
    "    del first; gc.collect()\n",
    "    return paths, mp4_path, (gif_path or \"\")\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Run the animation builder\n",
    "# ------------------------------\n",
    "# You can tweak fps (≤ 30 recommended) and duration_s (hard-capped at 15s).\n",
    "anim_cfg = _cfg  # reuse your config block above\n",
    "frame_list, mp4_out, gif_out = make_frames_density_to_cities(\n",
    "    anim_cfg,\n",
    "    total_duration_s=15.0,   # hard cap\n",
    "    fps=15,                  # 15 fps → up to 225 frames in 15s\n",
    "    frames_dir_name=\"frames\",# frames saved here\n",
    "    also_gif=True            # set False if you only want MP4\n",
    ")\n",
    "\n",
    "print(f\"\\nSaved {len(frame_list)} frames in: {os.path.join(anim_cfg.out_dir, 'frames')}\")\n",
    "print(f\"MP4: {mp4_out}\")\n",
    "if gif_out:\n",
    "    print(f\"GIF: {gif_out}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2042630a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building V1 frames: 100%|██████████| 224/224 [00:44<00:00,  5.03it/s]\n",
      "Encoding MP4: 100%|██████████| 225/225 [00:04<00:00, 50.79it/s]\n",
      "Encoding GIF: 100%|██████████| 225/225 [00:01<00:00, 200.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 225 frames in: maps/sv1.1/dv0.2_v1_classes\\frames_v1\n",
      "MP4: maps/sv1.1/dv0.2_v1_classes\\nodes_v1_classes.mp4\n",
      "GIF: maps/sv1.1/dv0.2_v1_classes\\nodes_v1_classes.gif\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Jupyter notebook cell — Version 1 (Nodes only)\n",
    "Probabilistic city classes + uniform population ranges per class.\n",
    "- Placement: uniform within bbox (same as V0)\n",
    "- Class assignment: per-node categorical draw with probabilities\n",
    "- Population: uniform integer in [min, max] for the node’s class\n",
    "- Outputs: nodes.csv, meta.json, preview.png (color = population; marker shape = class)\n",
    "\n",
    "Usage: run this cell. Edit `V1Config` to change class probabilities or ranges.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Tuple, Dict, Any, List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Config\n",
    "# ------------------------------\n",
    "@dataclass\n",
    "class V1Config:\n",
    "    seed: int = 42\n",
    "    n_nodes: int = 120\n",
    "    bbox_km: Tuple[float, float, float, float] = (0.0, 0.0, 200.0, 200.0)  # (minx, miny, maxx, maxy)\n",
    "\n",
    "    # Per-class probabilities (will be normalized to sum 1). Each node draws its class independently.\n",
    "    class_prob: Dict[str, float] = field(\n",
    "        default_factory=lambda: {\"large\": 0.10, \"medium\": 0.30, \"small\": 0.60}\n",
    "    )\n",
    "\n",
    "    # Uniform population ranges per class (inclusive of min/max)\n",
    "    class_ranges: Dict[str, Dict[str, int]] = field(\n",
    "        default_factory=lambda: {\n",
    "            # Choose non-overlapping ranges so medians satisfy large > medium > small\n",
    "            \"large\":  {\"min\": 600_000, \"max\": 1_500_000},\n",
    "            \"medium\": {\"min\": 150_000, \"max\":   500_000},\n",
    "            \"small\":  {\"min\":   1_000, \"max\":   120_000},\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Output & metadata\n",
    "    out_dir: str = \"maps/sv1.1/dv0.2_v1_classes_prob_uniform\"\n",
    "    crs: str = \"EPSG:3857\"  # Synthetic planar; coordinates stored in km for simplicity\n",
    "    schema_version: str = \"1.1\"  # still includes optional `class` column\n",
    "    dataset_version: str = \"0.2\"\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Core helpers\n",
    "# ------------------------------\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def generate_positions_uniform(bbox_km: Tuple[float, float, float, float], n: int) -> np.ndarray:\n",
    "    minx, miny, maxx, maxy = bbox_km\n",
    "    if not (minx < maxx and miny < maxy):\n",
    "        raise ValueError(\"Invalid bbox: must satisfy minx<maxx and miny<maxy\")\n",
    "    xs = np.random.uniform(minx, maxx, size=n)\n",
    "    ys = np.random.uniform(miny, maxy, size=n)\n",
    "    return np.column_stack([xs, ys])\n",
    "\n",
    "\n",
    "def _sample_classes(n: int, class_prob: Dict[str, float]) -> List[str]:\n",
    "    labels = list(class_prob.keys())\n",
    "    probs = np.array([class_prob[k] for k in labels], dtype=float)\n",
    "    probs = probs / probs.sum()\n",
    "    draws = np.random.choice(labels, size=n, p=probs)\n",
    "    return draws.tolist()\n",
    "\n",
    "\n",
    "def _sample_uniform_int(low: int, high: int, size: int) -> np.ndarray:\n",
    "    \"\"\"Inclusive uniform integer sampling in [low, high].\"\"\"\n",
    "    if high < low:\n",
    "        raise ValueError(f\"Invalid range: [{low},{high}]\")\n",
    "    return np.random.randint(low, high + 1, size=size, dtype=int)\n",
    "\n",
    "\n",
    "def generate_nodes_v1(cfg: V1Config) -> pd.DataFrame:\n",
    "    # positions\n",
    "    pts = generate_positions_uniform(cfg.bbox_km, cfg.n_nodes)\n",
    "\n",
    "    # classes (probabilistic per-node)\n",
    "    classes = _sample_classes(cfg.n_nodes, cfg.class_prob)\n",
    "\n",
    "    # populations per class (uniform within class range)\n",
    "    pops = np.empty(cfg.n_nodes, dtype=int)\n",
    "    for cls in cfg.class_prob.keys():\n",
    "        idx = [i for i, c in enumerate(classes) if c == cls]\n",
    "        if not idx:\n",
    "            continue\n",
    "        r = cfg.class_ranges.get(cls, None)\n",
    "        if r is None:\n",
    "            raise KeyError(f\"Missing class range for '{cls}'\")\n",
    "        pops[idx] = _sample_uniform_int(int(r[\"min\"]), int(r[\"max\"]), size=len(idx))\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": np.arange(cfg.n_nodes, dtype=int),\n",
    "        \"x_km\": pts[:, 0],\n",
    "        \"y_km\": pts[:, 1],\n",
    "        \"class\": classes,\n",
    "        \"pop\": pops,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_nodes(df: pd.DataFrame, cfg: V1Config) -> Dict[str, Any]:\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "    metrics: Dict[str, Any] = {}\n",
    "\n",
    "    # Count\n",
    "    n = len(df)\n",
    "    if n != cfg.n_nodes:\n",
    "        raise AssertionError(f\"Node count mismatch: expected {cfg.n_nodes}, got {n}\")\n",
    "    metrics[\"n_nodes\"] = n\n",
    "\n",
    "    # Bounds\n",
    "    inside_x = (df[\"x_km\"] >= minx) & (df[\"x_km\"] <= maxx)\n",
    "    inside_y = (df[\"y_km\"] >= miny) & (df[\"y_km\"] <= maxy)\n",
    "    violations = int((~(inside_x & inside_y)).sum())\n",
    "    if violations:\n",
    "        raise AssertionError(f\"{violations} nodes fall outside bbox\")\n",
    "    metrics[\"bbox\"] = {\"minx\": minx, \"miny\": miny, \"maxx\": maxx, \"maxy\": maxy}\n",
    "\n",
    "    # Class counts (no strict quota check; just report)\n",
    "    metrics[\"class_counts\"] = df[\"class\"].value_counts().to_dict()\n",
    "\n",
    "    # Population summaries and median ordering (should hold if ranges are non-overlapping)\n",
    "    med = df.groupby(\"class\")[\"pop\"].median().to_dict()\n",
    "    metrics[\"class_medians\"] = {k: int(v) for k, v in med.items()}\n",
    "    try:\n",
    "        if not (med[\"large\"] > med[\"medium\"] > med[\"small\"]):\n",
    "            # Don’t hard fail, just record a flag\n",
    "            metrics[\"median_order_ok\"] = False\n",
    "        else:\n",
    "            metrics[\"median_order_ok\"] = True\n",
    "    except KeyError:\n",
    "        metrics[\"median_order_ok\"] = False\n",
    "\n",
    "    # Global population range\n",
    "    pmin, pmax = int(df[\"pop\"].min()), int(df[\"pop\"].max())\n",
    "    metrics[\"pop_range_observed\"] = {\"min\": pmin, \"max\": pmax}\n",
    "    metrics[\"pop_percentiles\"] = {q: int(np.percentile(df[\"pop\"], q)) for q in (5, 25, 50, 75, 95)}\n",
    "\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def preview_nodes(df: pd.DataFrame, cfg: V1Config, save_path: str) -> None:\n",
    "    \"\"\"Scatter sized by population (color = population, colorbar legend).\n",
    "    Marker shape encodes class ({large: square, medium: triangle, small: circle}).\n",
    "    Annotates the top-3 most populated cities with population labels.\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "\n",
    "    vmax = df[\"pop\"].max()\n",
    "    vmin = df[\"pop\"].min()\n",
    "\n",
    "    markers = {\"large\": \"s\", \"medium\": \"^\", \"small\": \"o\"}\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "\n",
    "    sc = None\n",
    "    for cls in [\"large\", \"medium\", \"small\"]:\n",
    "        sub = df[df[\"class\"] == cls]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        sc = plt.scatter(\n",
    "            sub[\"x_km\"],\n",
    "            sub[\"y_km\"],\n",
    "            s=10 + 90 * np.sqrt(sub[\"pop\"].values / vmax),\n",
    "            c=sub[\"pop\"].values.astype(float),\n",
    "            vmin=vmin,\n",
    "            vmax=vmax,\n",
    "            marker=markers.get(cls, \"o\"),\n",
    "            label=cls.title(),\n",
    "        )\n",
    "\n",
    "    if sc is not None:\n",
    "        cbar = plt.colorbar(sc)\n",
    "        cbar.set_label(\"Population\")\n",
    "        try:\n",
    "            cbar.ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    handles = [Line2D([], [], marker=markers.get(cls, \"o\"), linestyle=\"None\", label=cls.title())\n",
    "               for cls in [\"large\", \"medium\", \"small\"]]\n",
    "    plt.legend(handles=handles, title=\"Class\", loc=\"best\", framealpha=0.8)\n",
    "\n",
    "    # Annotate top-3 by population\n",
    "    top3 = df.nlargest(3, \"pop\").copy()\n",
    "    dx = 0.01 * (maxx - minx)\n",
    "    dy = 0.01 * (maxy - miny)\n",
    "    for _, row in top3.iterrows():\n",
    "        label = f\"{int(row['pop']):,}\"\n",
    "        plt.text(\n",
    "            row[\"x_km\"] + dx,\n",
    "            row[\"y_km\"] + dy,\n",
    "            label,\n",
    "            fontsize=8,\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "        )\n",
    "\n",
    "    plt.title(\"Nodes — V1 (probabilistic classes; uniform ranges)\")\n",
    "    plt.xlabel(\"x (km)\")\n",
    "    plt.ylabel(\"y (km)\")\n",
    "    plt.xlim(minx, maxx)\n",
    "    plt.ylim(miny, maxy)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def compute_metrics_hash(metrics: Dict[str, Any]) -> str:\n",
    "    blob = json.dumps(metrics, sort_keys=True).encode(\"utf-8\")\n",
    "    return hashlib.sha256(blob).hexdigest()[:16]\n",
    "\n",
    "\n",
    "def save_artifacts(df: pd.DataFrame, cfg: V1Config, metrics: Dict[str, Any]) -> Dict[str, str]:\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    nodes_path = os.path.join(cfg.out_dir, \"nodes.csv\")\n",
    "    preview_path = os.path.join(cfg.out_dir, \"preview.png\")\n",
    "    meta_path = os.path.join(cfg.out_dir, \"meta.json\")\n",
    "\n",
    "    df.to_csv(nodes_path, index=False)\n",
    "    preview_nodes(df, cfg, preview_path)\n",
    "\n",
    "    meta = {\n",
    "        \"schema_version\": cfg.schema_version,\n",
    "        \"dataset_version\": cfg.dataset_version,\n",
    "        \"crs\": cfg.crs,\n",
    "        \"seed\": cfg.seed,\n",
    "        \"generator\": {\n",
    "            \"name\": \"nodes_v1_classes_prob_uniform\",\n",
    "            \"params\": {\n",
    "                \"n_nodes\": cfg.n_nodes,\n",
    "                \"bbox_km\": cfg.bbox_km,\n",
    "                \"class_prob\": cfg.class_prob,\n",
    "                \"class_ranges\": cfg.class_ranges,\n",
    "            },\n",
    "        },\n",
    "        \"region_bbox\": list(cfg.bbox_km),\n",
    "        \"metrics\": metrics,\n",
    "        \"metrics_hash\": compute_metrics_hash(metrics),\n",
    "        \"created_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    }\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    return {\"nodes\": nodes_path, \"preview\": preview_path, \"meta\": meta_path}\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Orchestration\n",
    "# ------------------------------\n",
    "\n",
    "def main(cfg: V1Config | None = None) -> pd.DataFrame:\n",
    "    cfg = cfg or V1Config()\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    df = generate_nodes_v1(cfg)\n",
    "    metrics = validate_nodes(df, cfg)\n",
    "    paths = save_artifacts(df, cfg, metrics)\n",
    "\n",
    "    print(\"\\n[Nodes V1] Build complete:\\n\" + \"-\" * 40)\n",
    "    print(f\"Nodes: {len(df)} | bbox: {cfg.bbox_km}\")\n",
    "    print(f\"Class counts: {metrics['class_counts']}\")\n",
    "    print(f\"Class medians: {metrics['class_medians']} (order ok = {metrics.get('median_order_ok')})\")\n",
    "    print(f\"Saved: nodes → {paths['nodes']}\\n       preview → {paths['preview']}\\n       meta → {paths['meta']}\")\n",
    "    print(f\"Metrics hash: {compute_metrics_hash(metrics)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Run (notebook-friendly)\n",
    "# ------------------------------\n",
    "_cfg = V1Config(\n",
    "    seed=30,\n",
    "    n_nodes=30,\n",
    "    bbox_km=(0.0, 0.0, 200.0, 200.0),\n",
    "    class_prob={\"large\": 0.10, \"medium\": 0.30, \"small\": 0.60},\n",
    "    class_ranges={\n",
    "        \"large\":  {\"min\": 600_000, \"max\": 1_500_000},\n",
    "        \"medium\": {\"min\": 100_000, \"max\":   300_000},\n",
    "        \"small\":  {\"min\":   1_000, \"max\":   60_000},\n",
    "    },\n",
    "    out_dir=\"maps/sv1.1/dv0.2_v1_classes\",\n",
    ")\n",
    "\n",
    "# Jupyter notebook cell — Animation V1 (classes → scatter growth, 15s, MP4+GIF)\n",
    "from __future__ import annotations\n",
    "import os, gc\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- encoders (required) ---\n",
    "import cv2                  # MP4\n",
    "import imageio.v2 as imageio  # GIF\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ease_in_out(t: np.ndarray, power: float = 2.2) -> np.ndarray:\n",
    "    t = np.clip(t, 0.0, 1.0)\n",
    "    a = t**power / (t**power + (1 - t)**power)\n",
    "    a[np.isnan(a)] = 0.0\n",
    "    return a\n",
    "\n",
    "def _plot_partial_v1(df, cfg, save_path, reveal_frac: float, grow: float,\n",
    "                     vmin: float, vmax: float) -> None:\n",
    "    \"\"\"\n",
    "    Dibuja un frame parcial:\n",
    "      - reveal_frac: fracción de nodos visibles (0..1) en orden por clase small→medium→large\n",
    "      - grow: factor de crecimiento de tamaño (0.05..1.0) para los visibles\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "    markers = {\"large\": \"s\", \"medium\": \"^\", \"small\": \"o\"}\n",
    "    order = [\"small\", \"medium\", \"large\"]\n",
    "\n",
    "    # Orden estable por clase y, dentro de cada clase, por población ascendente (estético)\n",
    "    parts = [df[df[\"class\"] == cls].sort_values(\"pop\") for cls in order]\n",
    "    df_ord = np.concatenate([p.index.values for p in parts])\n",
    "    df_ord = df.loc[df_ord]\n",
    "\n",
    "    n = len(df_ord)\n",
    "    k = max(1, int(np.floor(reveal_frac * n)))\n",
    "    shown = df_ord.iloc[:k].copy()\n",
    "\n",
    "    vmax_pop = df[\"pop\"].max()\n",
    "    base_sizes = 10 + 90 * np.sqrt(shown[\"pop\"].values / vmax_pop)\n",
    "    sizes = base_sizes * np.clip(grow, 0.05, 1.0)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sc_last = None\n",
    "    for cls in order:\n",
    "        sub = shown[shown[\"class\"] == cls]\n",
    "        if sub.empty:\n",
    "            continue\n",
    "        sc_last = plt.scatter(\n",
    "            sub[\"x_km\"], sub[\"y_km\"],\n",
    "            s=sizes[shown[\"class\"] == cls],\n",
    "            c=sub[\"pop\"].values.astype(float), vmin=vmin, vmax=vmax,\n",
    "            marker=markers.get(cls, \"o\"), cmap=\"viridis\", label=cls.title()\n",
    "        )\n",
    "\n",
    "    if sc_last is not None:\n",
    "        cbar = plt.colorbar(sc_last)\n",
    "        cbar.set_label(\"Population\")\n",
    "        try:\n",
    "            cbar.ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    handles = [Line2D([], [], marker=markers.get(cls, \"o\"), linestyle=\"None\", label=cls.title())\n",
    "               for cls in order]\n",
    "    plt.legend(handles=handles, title=\"Class\", loc=\"best\", framealpha=0.8)\n",
    "\n",
    "    plt.title(\"Nodes — V1 (probabilistic classes; uniform ranges)\")\n",
    "    plt.xlabel(\"x (km)\"); plt.ylabel(\"y (km)\")\n",
    "    plt.xlim(minx, maxx); plt.ylim(miny, maxy)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def make_v1_animation(cfg,\n",
    "                      total_duration_s: float = 15.0,\n",
    "                      fps: int = 15,\n",
    "                      frames_dir_name: str = \"frames_v1\") -> Tuple[List[str], str, str]:\n",
    "    \"\"\"\n",
    "    Genera frames + MP4 + GIF (siempre) para V1.\n",
    "    - Duración EXACTA: min(total_duration_s, 15s)\n",
    "    - Último frame = preview final (mismo estilo que preview_nodes)\n",
    "    \"\"\"\n",
    "    # 1) Datos deterministas (usa tu seed del cfg)\n",
    "    set_seed(cfg.seed)\n",
    "    df = generate_nodes_v1(cfg)\n",
    "\n",
    "    # 2) Carpetas\n",
    "    out_dir = cfg.out_dir\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    frames_dir = os.path.join(out_dir, frames_dir_name)\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "    # 3) Timing: N-1 frames de \"build\" + 1 frame final = total exacto\n",
    "    duration = min(15.0, float(total_duration_s))\n",
    "    total_frames = max(2, int(duration * fps))\n",
    "    n_build = total_frames - 1\n",
    "\n",
    "    # Escalado de color global\n",
    "    vmin, vmax = float(df[\"pop\"].min()), float(df[\"pop\"].max())\n",
    "\n",
    "    # 4) Frames de construcción\n",
    "    paths = []\n",
    "    t = _ease_in_out(np.linspace(0.0, 1.0, n_build), power=2.0)\n",
    "    for i, r in enumerate(tqdm(t, total=n_build, desc=\"Building V1 frames\")):\n",
    "        frame_path = os.path.join(frames_dir, f\"frame_{i:04d}.png\")\n",
    "        _plot_partial_v1(df, cfg, frame_path, reveal_frac=float(r), grow=float(r),\n",
    "                         vmin=vmin, vmax=vmax)\n",
    "        paths.append(frame_path)\n",
    "\n",
    "    # 5) Último frame = preview completo (garantiza coincidencia con preview.png)\n",
    "    final_path = os.path.join(frames_dir, f\"frame_{n_build:04d}.png\")\n",
    "    preview_nodes(df, cfg, final_path)  # reutiliza tu función existente\n",
    "    paths.append(final_path)\n",
    "\n",
    "    # 6) MP4 (siempre)\n",
    "    mp4_path = os.path.join(out_dir, \"nodes_v1_classes.mp4\")\n",
    "    first = cv2.imread(paths[0])\n",
    "    if first is None:\n",
    "        raise RuntimeError(\"Cannot read first frame for video encoding.\")\n",
    "    H, W = first.shape[:2]\n",
    "    writer = cv2.VideoWriter(mp4_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (W, H))\n",
    "    if not writer.isOpened():\n",
    "        raise RuntimeError(\"Failed to open VideoWriter for MP4.\")\n",
    "    for p in tqdm(paths, desc=\"Encoding MP4\"):\n",
    "        im = cv2.imread(p)\n",
    "        if im is None:\n",
    "            continue\n",
    "        if im.shape[:2] != (H, W):\n",
    "            im = cv2.resize(im, (W, H), interpolation=cv2.INTER_AREA)\n",
    "        writer.write(im)\n",
    "    writer.release()\n",
    "\n",
    "    # 7) GIF (siempre)\n",
    "    gif_path = os.path.join(out_dir, \"nodes_v1_classes.gif\")\n",
    "    with imageio.get_writer(gif_path, mode=\"I\", duration=1.0 / fps) as gifw:\n",
    "        for p in tqdm(paths, desc=\"Encoding GIF\"):\n",
    "            gifw.append_data(imageio.imread(p))\n",
    "\n",
    "    # Limpieza\n",
    "    del first; gc.collect()\n",
    "\n",
    "    return paths, mp4_path, gif_path\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Ejecutar el builder (15s exactos)\n",
    "# ------------------------------\n",
    "anim_cfg_v1 = _cfg  # reutiliza tu configuración V1 de arriba\n",
    "frame_list_v1, mp4_out_v1, gif_out_v1 = make_v1_animation(\n",
    "    anim_cfg_v1,\n",
    "    total_duration_s=15.0,   # EXACTO 15s\n",
    "    fps=15,                  # 225 frames → 15s\n",
    "    frames_dir_name=\"frames_v1\"\n",
    ")\n",
    "\n",
    "print(f\"\\nSaved {len(frame_list_v1)} frames in: {os.path.join(anim_cfg_v1.out_dir, 'frames_v1')}\")\n",
    "print(f\"MP4: {mp4_out_v1}\")\n",
    "print(f\"GIF: {gif_out_v1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a146bf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building V0 frames: 100%|██████████| 224/224 [00:24<00:00,  9.19it/s]\n",
      "Encoding MP4: 100%|██████████| 225/225 [00:05<00:00, 44.97it/s]\n",
      "Encoding GIF: 100%|██████████| 225/225 [00:01<00:00, 208.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved 225 frames in: maps/sv1.0/dv0.1_v0_uniform\\frames_v0\n",
      "MP4: maps/sv1.0/dv0.1_v0_uniform\\nodes_v0_uniform.mp4\n",
      "GIF: maps/sv1.0/dv0.1_v0_uniform\\nodes_v0_uniform.gif\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Jupyter notebook cell — Version 0 (Nodes only)\n",
    "Minimal, reproducible node set in a rectangular region (planar coordinates in km).\n",
    "- Placement: uniform within bbox\n",
    "- Population: uniform in [pop_min, pop_max]\n",
    "- Outputs: nodes.csv, meta.json, preview.png\n",
    "\n",
    "Usage (in a single notebook cell): just run this cell. Edit `V0Config` as needed.\n",
    "\"\"\"\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import hashlib\n",
    "from dataclasses import asdict, dataclass\n",
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Config\n",
    "# ------------------------------\n",
    "@dataclass\n",
    "class V0Config:\n",
    "    seed: int = 42\n",
    "    n_nodes: int = 50\n",
    "    bbox_km: Tuple[float, float, float, float] = (0.0, 0.0, 200.0, 200.0)  # (minx, miny, maxx, maxy)\n",
    "    pop_min: int = 1_000\n",
    "    pop_max: int = 500_000\n",
    "    out_dir: str = \"maps/sv1.0/dv0.1_v0_uniform\"\n",
    "    crs: str = \"EPSG:3857\"  # Synthetic planar meters; we store km here for simplicity\n",
    "    schema_version: str = \"1.0\"  # node schema version\n",
    "    dataset_version: str = \"0.1\"  # dataset/edition version\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Core functions\n",
    "# ------------------------------\n",
    "\n",
    "def set_seed(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "\n",
    "\n",
    "def generate_uniform_nodes(cfg: V0Config) -> pd.DataFrame:\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "    if not (minx < maxx and miny < maxy):\n",
    "        raise ValueError(\"Invalid bbox: must satisfy minx<maxx and miny<maxy\")\n",
    "\n",
    "    # sample coordinates uniformly in km\n",
    "    xs = np.random.uniform(minx, maxx, size=cfg.n_nodes)\n",
    "    ys = np.random.uniform(miny, maxy, size=cfg.n_nodes)\n",
    "\n",
    "    # sample populations uniformly (ints)\n",
    "    pops = np.random.randint(cfg.pop_min, cfg.pop_max + 1, size=cfg.n_nodes)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"id\": np.arange(cfg.n_nodes, dtype=int),\n",
    "        \"x_km\": xs,\n",
    "        \"y_km\": ys,\n",
    "        \"pop\": pops,\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_nodes(df: pd.DataFrame, cfg: V0Config) -> Dict[str, Any]:\n",
    "    \"\"\"Return validation metrics and raise on hard failures.\"\"\"\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "\n",
    "    metrics: Dict[str, Any] = {}\n",
    "    # Count\n",
    "    n = len(df)\n",
    "    if n != cfg.n_nodes:\n",
    "        raise AssertionError(f\"Node count mismatch: expected {cfg.n_nodes}, got {n}\")\n",
    "    metrics[\"n_nodes\"] = n\n",
    "\n",
    "    # Bounds\n",
    "    inside_x = (df[\"x_km\"] >= minx) & (df[\"x_km\"] <= maxx)\n",
    "    inside_y = (df[\"y_km\"] >= miny) & (df[\"y_km\"] <= maxy)\n",
    "    inside = inside_x & inside_y\n",
    "    violations = int((~inside).sum())\n",
    "    if violations:\n",
    "        raise AssertionError(f\"{violations} nodes fall outside bbox\")\n",
    "    metrics[\"bbox\"] = {\"minx\": minx, \"miny\": miny, \"maxx\": maxx, \"maxy\": maxy}\n",
    "\n",
    "    # Population range\n",
    "    pmin, pmax = int(df[\"pop\"].min()), int(df[\"pop\"].max())\n",
    "    if pmin < cfg.pop_min or pmax > cfg.pop_max:\n",
    "        raise AssertionError(\n",
    "            f\"Population out of range: observed [{pmin},{pmax}] vs cfg [{cfg.pop_min},{cfg.pop_max}]\"\n",
    "        )\n",
    "    metrics[\"pop_range_observed\"] = {\"min\": pmin, \"max\": pmax}\n",
    "\n",
    "    # Distribution summaries\n",
    "    metrics[\"pop_percentiles\"] = {q: int(np.percentile(df[\"pop\"], q)) for q in (5, 25, 50, 75, 95)}\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def preview_nodes(df: pd.DataFrame, cfg: V0Config, save_path: str) -> None:\n",
    "    \"\"\"Scatter plot sized by population with a color gradient and colorbar legend.\n",
    "    Also annotates the top-3 most populated cities with their population values.\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "\n",
    "\n",
    "    # size scaling: sqrt to reduce dynamic range\n",
    "    s = 10 + 90 * np.sqrt(df[\"pop\"].values / df[\"pop\"].max())\n",
    "\n",
    "\n",
    "    # Color by population (uses matplotlib's default colormap)\n",
    "    pop_vals = df[\"pop\"].values.astype(float)\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sc = plt.scatter(df[\"x_km\"], df[\"y_km\"], s=s, c=pop_vals)\n",
    "\n",
    "\n",
    "    # Colorbar as legend for population\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"Population\")\n",
    "    try:\n",
    "        cbar.ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    except Exception:\n",
    "        pass # fallback to default ticks if formatter not available\n",
    "\n",
    "\n",
    "    # Annotate top-3 by population\n",
    "    top3 = df.nlargest(3, \"pop\").copy()\n",
    "    # Offset annotations by a small fraction of the bbox size to avoid overlap\n",
    "    dx = 0.01 * (maxx - minx)\n",
    "    dy = 0.01 * (maxy - miny)\n",
    "    for _, row in top3.iterrows():\n",
    "        label = f\"{int(row['pop']):,}\"\n",
    "        plt.text(\n",
    "            row[\"x_km\"] + dx,\n",
    "            row[\"y_km\"] + dy,\n",
    "            label,\n",
    "            fontsize=8,\n",
    "            ha=\"left\",\n",
    "            va=\"bottom\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.2\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "        )\n",
    "\n",
    "\n",
    "    plt.title(\"Nodes — V0 (uniform placement) — color = population\")\n",
    "    plt.xlabel(\"x (km)\")\n",
    "    plt.ylabel(\"y (km)\")\n",
    "    plt.xlim(minx, maxx)\n",
    "    plt.ylim(miny, maxy)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def compute_metrics_hash(metrics: Dict[str, Any]) -> str:\n",
    "    blob = json.dumps(metrics, sort_keys=True).encode(\"utf-8\")\n",
    "    return hashlib.sha256(blob).hexdigest()[:16]\n",
    "\n",
    "\n",
    "def save_artifacts(df: pd.DataFrame, cfg: V0Config, metrics: Dict[str, Any]) -> Dict[str, str]:\n",
    "    os.makedirs(cfg.out_dir, exist_ok=True)\n",
    "\n",
    "    nodes_path = os.path.join(cfg.out_dir, \"nodes.csv\")\n",
    "    preview_path = os.path.join(cfg.out_dir, \"preview.png\")\n",
    "    meta_path = os.path.join(cfg.out_dir, \"meta.json\")\n",
    "\n",
    "    # Save nodes\n",
    "    df.to_csv(nodes_path, index=False)\n",
    "\n",
    "    # Preview\n",
    "    preview_nodes(df, cfg, preview_path)\n",
    "\n",
    "    # Meta\n",
    "    meta = {\n",
    "        \"schema_version\": cfg.schema_version,\n",
    "        \"dataset_version\": cfg.dataset_version,\n",
    "        \"crs\": cfg.crs,\n",
    "        \"seed\": cfg.seed,\n",
    "        \"generator\": {\n",
    "            \"name\": \"nodes_v0_uniform\",\n",
    "            \"params\": {\n",
    "                \"n_nodes\": cfg.n_nodes,\n",
    "                \"bbox_km\": cfg.bbox_km,\n",
    "                \"pop_min\": cfg.pop_min,\n",
    "                \"pop_max\": cfg.pop_max,\n",
    "            },\n",
    "        },\n",
    "        \"region_bbox\": list(cfg.bbox_km),\n",
    "        \"metrics\": metrics,\n",
    "        \"metrics_hash\": compute_metrics_hash(metrics),\n",
    "        \"created_at_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    }\n",
    "    with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(meta, f, indent=2)\n",
    "\n",
    "    return {\"nodes\": nodes_path, \"preview\": preview_path, \"meta\": meta_path}\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Orchestration\n",
    "# ------------------------------\n",
    "\n",
    "def main(cfg: V0Config | None = None) -> pd.DataFrame:\n",
    "    cfg = cfg or V0Config()\n",
    "    set_seed(cfg.seed)\n",
    "\n",
    "    df = generate_uniform_nodes(cfg)\n",
    "    metrics = validate_nodes(df, cfg)\n",
    "    paths = save_artifacts(df, cfg, metrics)\n",
    "\n",
    "    # Summary printout\n",
    "    print(\"\\n[Nodes V0] Build complete:\\n\" + \"-\" * 40)\n",
    "    print(f\"Nodes: {len(df)} | bbox: {cfg.bbox_km} | pop ∈ [{cfg.pop_min},{cfg.pop_max}]\")\n",
    "    print(f\"Saved: nodes → {paths['nodes']}\\n       preview → {paths['preview']}\\n       meta → {paths['meta']}\")\n",
    "    print(f\"Metrics hash: {compute_metrics_hash(metrics)}\")\n",
    "    return df\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "_cfg = V0Config(\n",
    "    seed=42,\n",
    "    n_nodes=30,\n",
    "    bbox_km=(0.0, 0.0, 200.0, 200.0),\n",
    "    pop_min=1_000,\n",
    "    pop_max=1_000_000,\n",
    "    out_dir=\"maps/sv1.0/dv0.1_v0_uniform\",\n",
    ")\n",
    "\n",
    "# _ = main(_cfg)\n",
    "\n",
    "# Jupyter notebook cell — Animation V0 (uniform nodes), 15s, MP4+GIF, frames saved\n",
    "from __future__ import annotations\n",
    "import os, gc\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import StrMethodFormatter\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Encoders (requeridos)\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _ease_in_out(t: np.ndarray, power: float = 2.2) -> np.ndarray:\n",
    "    t = np.clip(t, 0.0, 1.0)\n",
    "    a = t**power / (t**power + (1 - t)**power)\n",
    "    a[np.isnan(a)] = 0.0\n",
    "    return a\n",
    "\n",
    "def _plot_partial_v0(df, cfg: V0Config, save_path: str,\n",
    "                     reveal_frac: float, grow: float,\n",
    "                     vmin: float, vmax: float) -> None:\n",
    "    \"\"\"\n",
    "    Dibuja un frame parcial:\n",
    "      - reveal_frac ∈ [0..1]: fracción de nodos visibles (orden por población ascendente)\n",
    "      - grow: factor de crecimiento del tamaño (0.05..1.0) para los visibles\n",
    "    \"\"\"\n",
    "    minx, miny, maxx, maxy = cfg.bbox_km\n",
    "\n",
    "    # Orden estable por población ascendente (estético)\n",
    "    df_ord = df.sort_values(\"pop\")\n",
    "    n = len(df_ord)\n",
    "    k = max(1, int(np.floor(reveal_frac * n)))\n",
    "    shown = df_ord.iloc[:k].copy()\n",
    "\n",
    "    vmax_pop = df[\"pop\"].max()\n",
    "    base_sizes = 10 + 90 * np.sqrt(shown[\"pop\"].values / vmax_pop)\n",
    "    sizes = base_sizes * np.clip(grow, 0.05, 1.0)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sc = plt.scatter(\n",
    "        shown[\"x_km\"], shown[\"y_km\"],\n",
    "        s=sizes, c=shown[\"pop\"].values.astype(float),\n",
    "        vmin=vmin, vmax=vmax, cmap=\"viridis\"\n",
    "    )\n",
    "\n",
    "    cbar = plt.colorbar(sc)\n",
    "    cbar.set_label(\"Population\")\n",
    "    try:\n",
    "        cbar.ax.yaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    plt.title(\"Nodes — V0 (uniform placement) — color = population\")\n",
    "    plt.xlabel(\"x (km)\"); plt.ylabel(\"y (km)\")\n",
    "    plt.xlim(minx, maxx); plt.ylim(miny, maxy)\n",
    "    plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "def make_v0_animation(cfg: V0Config,\n",
    "                      total_duration_s: float = 15.0,\n",
    "                      fps: int = 15,\n",
    "                      frames_dir_name: str = \"frames_v0\") -> Tuple[List[str], str, str]:\n",
    "    \"\"\"\n",
    "    Genera frames + MP4 + GIF (siempre) para V0.\n",
    "    - Duración EXACTA: min(total_duration_s, 15s)\n",
    "    - Último frame = preview final (matching preview_nodes)\n",
    "    \"\"\"\n",
    "    # 1) Datos deterministas\n",
    "    set_seed(cfg.seed)\n",
    "    df = generate_uniform_nodes(cfg)\n",
    "\n",
    "    # 2) Carpetas\n",
    "    out_dir = cfg.out_dir\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    frames_dir = os.path.join(out_dir, frames_dir_name)\n",
    "    os.makedirs(frames_dir, exist_ok=True)\n",
    "\n",
    "    # 3) Timing\n",
    "    duration = min(15.0, float(total_duration_s))\n",
    "    total_frames = max(2, int(duration * fps))\n",
    "    n_build = total_frames - 1  # último = preview completo\n",
    "\n",
    "    # Escala de color global fija\n",
    "    vmin, vmax = float(df[\"pop\"].min()), float(df[\"pop\"].max())\n",
    "\n",
    "    # 4) Frames de construcción (reveal + grow)\n",
    "    paths: List[str] = []\n",
    "    t = _ease_in_out(np.linspace(0.0, 1.0, n_build), power=2.0)\n",
    "    for i, r in enumerate(tqdm(t, total=n_build, desc=\"Building V0 frames\")):\n",
    "        frame_path = os.path.join(frames_dir, f\"frame_{i:04d}.png\")\n",
    "        _plot_partial_v0(df, cfg, frame_path, reveal_frac=float(r), grow=float(r),\n",
    "                         vmin=vmin, vmax=vmax)\n",
    "        paths.append(frame_path)\n",
    "\n",
    "    # 5) Último frame = preview completo (con anotaciones top-3)\n",
    "    final_path = os.path.join(frames_dir, f\"frame_{n_build:04d}.png\")\n",
    "    preview_nodes(df, cfg, final_path)\n",
    "    paths.append(final_path)\n",
    "\n",
    "    # 6) MP4 (siempre)\n",
    "    mp4_path = os.path.join(out_dir, \"nodes_v0_uniform.mp4\")\n",
    "    first = cv2.imread(paths[0])\n",
    "    if first is None:\n",
    "        raise RuntimeError(\"Cannot read first frame for MP4 encoding.\")\n",
    "    H, W = first.shape[:2]\n",
    "    writer = cv2.VideoWriter(mp4_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (W, H))\n",
    "    if not writer.isOpened():\n",
    "        raise RuntimeError(\"Failed to open VideoWriter.\")\n",
    "    for p in tqdm(paths, desc=\"Encoding MP4\"):\n",
    "        im = cv2.imread(p)\n",
    "        if im is None:\n",
    "            continue\n",
    "        if im.shape[:2] != (H, W):\n",
    "            im = cv2.resize(im, (W, H), interpolation=cv2.INTER_AREA)\n",
    "        writer.write(im)\n",
    "    writer.release()\n",
    "\n",
    "    # 7) GIF (siempre)\n",
    "    gif_path = os.path.join(out_dir, \"nodes_v0_uniform.gif\")\n",
    "    with imageio.get_writer(gif_path, mode=\"I\", duration=1.0 / fps) as gifw:\n",
    "        for p in tqdm(paths, desc=\"Encoding GIF\"):\n",
    "            gifw.append_data(imageio.imread(p))\n",
    "\n",
    "    del first; gc.collect()\n",
    "    return paths, mp4_path, gif_path\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# Ejecutar (15s exactos)\n",
    "# ------------------------------\n",
    "anim_cfg_v0 = _cfg  # reutiliza tu V0Config de arriba\n",
    "frame_list_v0, mp4_out_v0, gif_out_v0 = make_v0_animation(\n",
    "    anim_cfg_v0,\n",
    "    total_duration_s=15.0,   # EXACT 15s\n",
    "    fps=15,                  # 225 frames\n",
    "    frames_dir_name=\"frames_v0\"\n",
    ")\n",
    "\n",
    "print(f\"\\nSaved {len(frame_list_v0)} frames in: {os.path.join(anim_cfg_v0.out_dir, 'frames_v0')}\")\n",
    "print(f\"MP4: {mp4_out_v0}\")\n",
    "print(f\"GIF: {gif_out_v0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2de72064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building collage frames: 100%|██████████| 225/225 [00:06<00:00, 32.16it/s]\n",
      "Encoding MP4: 100%|██████████| 225/225 [00:07<00:00, 30.46it/s]\n",
      "Encoding GIF: 100%|██████████| 225/225 [00:03<00:00, 66.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frames: 225 → maps/collages/v0_v1_v2\\frames_collage\n",
      "MP4:    maps/collages/v0_v1_v2\\collage_uniform_classes_density.mp4\n",
      "GIF:    maps/collages/v0_v1_v2\\collage_uniform_classes_density.gif\n"
     ]
    }
   ],
   "source": [
    "# Jupyter notebook cell — Collage V0+V1+V2 → MP4+GIF (15s), frames guardados\n",
    "from __future__ import annotations\n",
    "import os, gc\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import imageio.v2 as imageio\n",
    "\n",
    "# Rutas por defecto (ajústalas si cambiaste out_dir/frames)\n",
    "DIR_V0 = \"maps/sv1.0/dv0.1_v0_uniform/frames_v0\"\n",
    "DIR_V1 = \"maps/sv1.1/dv0.2_v1_classes/frames_v1\"\n",
    "DIR_V2 = \"maps/sv1.2/dv0.1_v2_density_cities/frames\"\n",
    "\n",
    "OUT_DIR = \"maps/collages/v0_v1_v2\"\n",
    "FRAMES_OUT = os.path.join(OUT_DIR, \"frames_collage\")\n",
    "FPS = 15\n",
    "DURATION_S = 15.0  # exacto\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(FRAMES_OUT, exist_ok=True)\n",
    "\n",
    "def _list_pngs(d):\n",
    "    files = sorted([os.path.join(d, f) for f in os.listdir(d) if f.lower().endswith(\".png\")])\n",
    "    if not files:\n",
    "        raise RuntimeError(f\"No PNG frames found in: {d}\")\n",
    "    return files\n",
    "\n",
    "def _sample_indices(n, target):\n",
    "    # indices equiespaciados para asegurar EXACTAMENTE 15s aunque el nº de frames difiera\n",
    "    return np.rint(np.linspace(0, n - 1, target)).astype(int)\n",
    "\n",
    "def _resize_to_height(img, H):\n",
    "    h, w = img.shape[:2]\n",
    "    if h == H: \n",
    "        return img\n",
    "    new_w = int(round(w * (H / h)))\n",
    "    return cv2.resize(img, (new_w, H), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# 1) Cargar listas de frames\n",
    "f0 = _list_pngs(DIR_V0)\n",
    "f1 = _list_pngs(DIR_V1)\n",
    "f2 = _list_pngs(DIR_V2)\n",
    "\n",
    "target_frames = int(FPS * min(15.0, float(DURATION_S)))\n",
    "idx0 = _sample_indices(len(f0), target_frames)\n",
    "idx1 = _sample_indices(len(f1), target_frames)\n",
    "idx2 = _sample_indices(len(f2), target_frames)\n",
    "\n",
    "# 2) Determinar tamaño final leyendo el primer trío\n",
    "im0 = cv2.imread(f0[idx0[0]]); im1 = cv2.imread(f1[idx1[0]]); im2 = cv2.imread(f2[idx2[0]])\n",
    "if im0 is None or im1 is None or im2 is None:\n",
    "    raise RuntimeError(\"Failed to read first frames to determine canvas size.\")\n",
    "base_H = min(im0.shape[0], im1.shape[0], im2.shape[0])  # normalizamos por altura\n",
    "gutter_w = 6  # separador vertical\n",
    "gutter = lambda H: np.full((H, gutter_w, 3), 255, dtype=np.uint8)  # blanco\n",
    "\n",
    "# 3) Generar frames del collage\n",
    "frame_paths = []\n",
    "for i in tqdm(range(target_frames), desc=\"Building collage frames\"):\n",
    "    a = _resize_to_height(cv2.imread(f0[idx0[i]]), base_H)\n",
    "    b = _resize_to_height(cv2.imread(f1[idx1[i]]), base_H)\n",
    "    c = _resize_to_height(cv2.imread(f2[idx2[i]]), base_H)\n",
    "    canvas = np.concatenate([a, gutter(base_H), b, gutter(base_H), c], axis=1)\n",
    "    out_path = os.path.join(FRAMES_OUT, f\"frame_{i:04d}.png\")\n",
    "    cv2.imwrite(out_path, canvas)\n",
    "    frame_paths.append(out_path)\n",
    "\n",
    "# 4) MP4 (siempre)\n",
    "first = cv2.imread(frame_paths[0])\n",
    "H, W = first.shape[:2]\n",
    "mp4_path = os.path.join(OUT_DIR, \"collage_uniform_classes_density.mp4\")\n",
    "vw = cv2.VideoWriter(mp4_path, cv2.VideoWriter_fourcc(*\"mp4v\"), FPS, (W, H))\n",
    "if not vw.isOpened():\n",
    "    raise RuntimeError(\"Failed to open VideoWriter for MP4.\")\n",
    "for p in tqdm(frame_paths, desc=\"Encoding MP4\"):\n",
    "    img = cv2.imread(p)\n",
    "    if img.shape[:2] != (H, W):\n",
    "        img = cv2.resize(img, (W, H), interpolation=cv2.INTER_AREA)\n",
    "    vw.write(img)\n",
    "vw.release()\n",
    "\n",
    "# 5) GIF (siempre)\n",
    "gif_path = os.path.join(OUT_DIR, \"collage_uniform_classes_density.gif\")\n",
    "with imageio.get_writer(gif_path, mode=\"I\", duration=1.0 / FPS) as gifw:\n",
    "    for p in tqdm(frame_paths, desc=\"Encoding GIF\"):\n",
    "        gifw.append_data(imageio.imread(p))\n",
    "\n",
    "del first; gc.collect()\n",
    "print(f\"\\nFrames: {len(frame_paths)} → {FRAMES_OUT}\")\n",
    "print(f\"MP4:    {mp4_path}\")\n",
    "print(f\"GIF:    {gif_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
